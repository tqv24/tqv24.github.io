[{"authors":null,"categories":null,"content":"Duc Q. Nguyen, also known as Martin Nguyen, is currently a first‚Äëyear PhD student driven by a vision to amplify human potential through cutting‚Äëedge techniques, especially artificial intelligence. He was mentored by Sang T. Truong and supervised by Professor Sanmi Koyejo and Professor Tho Quan. His research interests include generative models, graph representation learning, and probabilistic machine learning.\nHis biggest ambition is to augment human capacity and better using his talent and experiences.\nDownload his resum√© .\n","date":1758117600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1758117600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"2025-09-15T08:00:00Z","relpermalink":"","section":"authors","summary":"Duc Q. Nguyen, also known as Martin Nguyen, is currently a first‚Äëyear PhD student driven by a vision to amplify human potential through cutting‚Äëedge techniques, especially artificial intelligence. He was mentored by Sang T.","tags":null,"title":"Duc Q. Nguyen","type":"authors"},{"authors":["Duc Q. Nguyen"],"categories":null,"content":"","date":1758117600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1758117600,"objectID":"c8b54292b1ecaf3ca6313c1c1cd79128","permalink":"https://martinakaduc.github.io/talk/a-practical-introduction-to-the-rational-speechact-modeling-framework/","publishdate":"2025-09-15T08:00:00Z","relpermalink":"/talk/a-practical-introduction-to-the-rational-speechact-modeling-framework/","section":"event","summary":"A seminar introducing the Rational Speech Act framework, which models language understanding as recursive Bayesian inference.","tags":["Cognitive Science","RSA Framework","Pragmatic Language Understanding","Bayesian Inference","Computational Modeling"],"title":"A Practical Introduction to The Rational SpeechAct Modeling Framework","type":"event"},{"authors":["Duc Q. Nguyen"],"categories":null,"content":"","date":1756476e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756476e3,"objectID":"dfc4b4264effe592bd1d07fd0e480844","permalink":"https://martinakaduc.github.io/talk/llms-get-lost-in-multi-turn-conversation/","publishdate":"2025-08-25T08:00:00Z","relpermalink":"/talk/llms-get-lost-in-multi-turn-conversation/","section":"event","summary":"A seminar about evaluating how large language models degrade in performance during multi-turn conversations due to premature assumptions and context loss.","tags":["Large Language Models","Multi-turn Dialogue","Benchmarking","Evaluation Methodology","Conversational AI","Natural Language Processing"],"title":"LLMs Get Lost In Multi-Turn Conversation","type":"event"},{"authors":["Duc Q. Nguyen"],"categories":null,"content":"","date":1755698400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1755698400,"objectID":"761786de35100df05e24ca48cda98b6a","permalink":"https://martinakaduc.github.io/talk/bayesian-theory-of-mind/","publishdate":"2025-08-19T08:00:00Z","relpermalink":"/talk/bayesian-theory-of-mind/","section":"event","summary":"A seminar for discussing the recent Bayesian Theory of Mind paper.","tags":["Cognitive Science"],"title":"Bayesian Theory of Mind","type":"event"},{"authors":["Duc Q. Nguyen"],"categories":null,"content":"Please join the meeting using the link above.\n","date":17487e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":17487e5,"objectID":"8a0bbf9889b3e93d8dc14e36d8d8de48","permalink":"https://martinakaduc.github.io/talk/absolutezero-reinforced-self-play-reasoning-with-zero-data/","publishdate":"2025-05-25T08:00:00Z","relpermalink":"/talk/absolutezero-reinforced-self-play-reasoning-with-zero-data/","section":"event","summary":"A seminar for discussing the recent AbsoluteZero paper.","tags":["Large Language Models","Reinforcement Learning","Natural Language Processing"],"title":"AbsoluteZero: Reinforced Self-play Reasoning with Zero Data","type":"event"},{"authors":["Duc Nguyen","Dong Le","Long Nguyen","Quyen Vu","Tran Le","Dung Nguyen","Nga Huynh","Huong Nguyen","Phat Tran","Dang Le","Sang Truong","Sanmi Koyejo","Cuong Le","Tho Quan"],"categories":["Education","AI Literacy"],"content":"","date":1746576e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746576e3,"objectID":"cbb21c7115cf6916a465e29b02e311a6","permalink":"https://martinakaduc.github.io/publication/riding-on-the-back-of-a-whale/","publishdate":"2025-05-07T00:00:00Z","relpermalink":"/publication/riding-on-the-back-of-a-whale/","section":"publication","summary":"As large language models (LLMs) become more integrated into daily life, it is crucial to foster AI literacy among high school stu- dents. However, most AI courses target college-level learners and assume prior knowledge, while high schools often lack the foundational curricu- lum and infrastructure for traditional LLM education. To bridge this gap, we present a hackathon-based framework that makes LLM learning acces- sible, engaging, and hands-on. The program combines interactive lectures on core LLM concepts with a guided competition where students fine- tune models and build real-world applications, such as healthcare chat- bots. This approach boosts motivation, programming skills, and practical understanding. Post-hackathon survey results show students gained both functional LLM experience and foundational knowledge. Furthermore, our framework can be extended to broader audiences, including learners without prior AI/NLP experience, offering a rapid, application-driven introduction to LLMs.","tags":["Large Language Models","Hackathon","Artificial Intelligence"],"title":"Riding on The Back of A Whale: A Hackathon Framework for Introducing High School Students to Large Language Models","type":"publication"},{"authors":["Duc Q. Nguyen"],"categories":["Academic"],"content":"The process of applying for a PhD program, particularly at toptier institutions like MIT or Stanford, often evokes a complex mix of anticipation, self-doubt, and prolonged waiting. For many applicants, this period is a time of hopelessness and dejection, as the outcome remains uncertain until the final decision is revealed. This experience is especially poignant for those who perceive themselves as ‚Äúordinary‚Äù candidates‚Äîindividuals without a litany of prestigious achievements, medals, or top-tier standardized test scores. Yet, the question persists: Is there a viable path for such candidates to secure admission, or does their chance resemble a statistical anomaly, akin to the rare occurrence of a black swan?\nThe Perception of Prestige and the ‚ÄúOrdinary‚Äù Applicant In current academia, admission to elite institutions is frequently associated with a well-documented profile of excellence. Successful applicants to Stanford, for instance, often boast an impressive array of accolades‚Äîresearch publications, international awards, and near-perfect academic records. This creates an imposing standard that can intimidate applicants whose strengths lie elsewhere. For a candidate with distinguished but unconventional experience‚Äîperhaps years of independent research, unique professional contributions, or resilience in overcoming personal challenges‚Äîthe prospect of standing out amidst such competition may feel daunting. The probability of acceptance for such an individual might appear small, leading to the judgment that it constitutes a black swan event: an improbable outcome that defies expectation.\nNonetheless, this perspective overlooks a critical reality of admissions processes. While excellent achievements undoubtedly enhance a candidate‚Äôs profile, many programs, including those at top-tier universities, value diversity of thought, experience, and potential. A ‚Äúnormal‚Äù applicant with a compelling narrative and demonstrated capacity for intellectual growth is not inherently excluded. The likelihood of success may be smaller than for those with traditional markers of excellence, but it is not negligible. Admissions committees are the treasure hunters trying their best to recognize the merit in candidates whose journeys deviate from the conventional path.\nSlow Blooming: A Testament to Persistence ‚ÄúSlow blooming does not mean no blooming‚Äù\nThis adage offers a poignant reminder during this difficult waiting period. Academic and personal development do not adhere to a universal timeline. For some, brilliance manifests early, reflected in a cascade of awards and recognition. For others, it emerges gradually, shaped by persistence, endeavor, and unconventional experiences. The PhD application process, though often framed as a meritocratic sprint, also rewards those who have cultivated their potential over time. A candidate who lacks a glittering resume but demonstrates depth, resilience, and a clear vision for their research may still secure a slot among other excellences. The key lies in articulating this journey effectively, transforming their ‚Äúseeming‚Äù ordinariness into a narrative of distinction.\nSchr√∂dinger‚Äôs Cat and the PhD-Application Waiting Game The interim from submitting a PhD application to receiving a decision bears a striking resemblance to the thought experiment of Schr√∂dinger‚Äôs cat. In quantum mechanics, the cat exists in a superposition‚Äîsimultaneously alive and dead‚Äîuntil the box is opened and its state observed. Similarly, during the ‚Äúdead‚Äù waiting period, an applicant occupies a liminal space, suspended between acceptance and rejection. The outcome is unknowable until the notification email is opened in the form of an admissions letter. This uncertainty can be profoundly disorienting, amplifying feelings of dejection as weeks stretch into months. Each passing day without news reinforces the sense of being trapped in a state of limbo, where hope and despair coexist in equal measure.\nYet, just as Schr√∂dinger‚Äôs paradox serves to illustrate the nature of observation, the PhD application waiting period underscores the importance of resilience. The applicant cannot alter the decision retroactively, but they can control their response to the uncertainty‚Äîmaintaining focus on their goals, refining their research interests, and preparing for multiple outcomes. This mindset transforms the waiting period from a passive ordeal into an active phase of growth. By embracing the unknown, the applicant cultivates the resilience needed to navigate the academic landscape, regardless of the final decision.\nEmbracing the Unknown The PhD application process, with its prolonged delays and multiple factors affecting it, tests the resolve of even the most determined candidates. For those without a traditional portfolio of achievements, the journey may feel particularly hopeless, the odds of success seemingly infinitesimal. However, the possibility of admission, though rare, is not illusory. Like a slow-blooming flower or the ‚Ä¶","date":1743034200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1743034200,"objectID":"b149054096b1349832ad6fa84d9c2dfc","permalink":"https://martinakaduc.github.io/post/phd-application/","publishdate":"2025-03-27T00:10:00Z","relpermalink":"/post/phd-application/","section":"post","summary":"The process of applying for a PhD program is such a Schr√∂dinger's cat experiment.","tags":["Personal","PhD Application"],"title":"The Prolonged Uncertainty of the PhD Application Period: Hope and Resilience","type":"post"},{"authors":["Sang T. Truong","Duc Q. Nguyen","Willie Neiswanger","Ryan-Rhys Griffiths","Stefano Ermon","Nick Haber","Sanmi Koyejo"],"categories":["Deep Learning","Probabilistic Machine Learning"],"content":"","date":174096e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":174096e4,"objectID":"db56c3299a861b11151881de7987a471","permalink":"https://martinakaduc.github.io/publication/neural-nonmyopic-bayesian-optimization-in-dynamic-cost-settings/","publishdate":"2025-03-03T00:00:00Z","relpermalink":"/publication/neural-nonmyopic-bayesian-optimization-in-dynamic-cost-settings/","section":"publication","summary":"Bayesian optimization (BO) is a popular framework for optimizing black-box functions, leveraging probabilistic models such as Gaussian processes. Conventional BO algorithms, however, assume static query costs, which limit their applicability to real-world problems with dynamic cost structures such as geological surveys or biological sequence design, where query costs vary based on the previous actions. We propose a novel nonmyopic BO algorithm named LookaHES featuring dynamic cost models to address this. LookaHES employs a neural network policy for variational optimization over multi-step lookahead horizons to enable planning under dynamic cost environments. Empirically, we benchmark LookaHES on synthetic functions exhibiting varied dynamic cost structures. We subsequently apply LookaHES to a real-world application in protein sequence design using a large language model policy, demonstrating its scalability and effectiveness in handling multi-step planning in a large and complex query space. LookaHES consistently outperforms its myopic counterparts in synthetic and real-world settings, significantly improving efficiency and solution quality.","tags":["Bayesian Optimization","Bioinformatics","Computer science","Deep Learning","Probabilistic Machine Learning","Nonmyopic Optimization","Large Language Models","Protein Sequence Design"],"title":"Neural Nonmyopic Bayesian Optimization in Dynamic Cost Settings","type":"publication"},{"authors":["Duc Q. Nguyen","Thanh-Toan Nguyen","Jun Jo","Florent Poux","Shikha Anirban","Tho T. Quan"],"categories":["Deep Learning","Graph Representation Learning"],"content":"","date":1726012800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726012800,"objectID":"081f6db07b7a56140ba536de68f39651","permalink":"https://martinakaduc.github.io/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/","publishdate":"2024-09-11T00:00:00Z","relpermalink":"/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/","section":"publication","summary":"Subgraph matching is a challenging problem with a wide range of applications in drug discovery, social network analysis, biochemistry, and cognitive science. It involves determining whether a given query graph is present within a larger target graph. Traditional graph-matching algorithms provide precise results but face challenges in large graph instances due to the NP-complete nature of the problem, limiting their practical applicability. In contrast, recent neural network-based approximations offer more scalable solutions but often lack interpretable node correspondences. To address these limitations, this article presents a multi-task learning framework called xNeuSM: Explainable Neural Subgraph Matching, which introduces Graph Learnable Multi-hop Attention Networks (GLeMA) that adaptively learn the parameters governing the attention factor decay for each node across hops rather than relying on fixed hyperparameters. Our framework jointly optimizes both subgraph matching and finding subgraph-isomorphism mappings. We provide a theoretical analysis establishing error bounds for GLeMA‚Äôs approximation of multi-hop attention as a function of the number of hops. Additionally, we prove that learning distinct attention decay factors for each node leads to a correct approximation of multi-hop attention. Empirical evaluation on real-world datasets shows that xNeuSM achieves substantial improvements in prediction F1 score of up to 34% compared to approximate baselines and, notably, at least a seven-fold faster query time than exact algorithms. With these results, xNeuSM can be applied to solve matching problems in various domains spanning from biochemistry to social science","tags":["Graph Neural Network","Subgraph Isomorphism","Artificial Intelligence"],"title":"Explainable Neural Subgraph Matching With Learnable Multi-Hop Attention","type":"publication"},{"authors":["Sang T. Truong","Duc Q. Nguyen","Toan Nguyen","Dong D. Le","Nhi N. Truong","Tho Quan","Sanmi Koyejo"],"categories":["Deep Learning"],"content":"","date":1718582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718582400,"objectID":"bd743883845c5aa71e028ccea5f8a230","permalink":"https://martinakaduc.github.io/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/","publishdate":"2024-06-17T00:00:00Z","relpermalink":"/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/","section":"publication","summary":"Recent advancements in large language models (LLMs) have underscored their importance in the evolution of artificial intelligence. However, despite extensive pretraining on multilingual datasets, available open-sourced LLMs exhibit limited effectiveness in processing Vietnamese. The challenge is exacerbated by the absence of systematic benchmark datasets and metrics tailored for Vietnamese LLM evaluation. To mitigate these issues, we have finetuned LLMs specifically for Vietnamese and developed a comprehensive evaluation framework encompassing 10 tasks and 31 metrics. We observe that finetuning can help LLMs transfer knowledge across languages, serving as an efficient way to bolster their capabilities in non-English languages. Moreover, our analysis indicates that larger models can introduce more biases and uncalibrated outputs and the key factor influencing LLM performance is the quality of the training or finetuning datasets. These insights underscore the significance of meticulous finetuning with high-quality datasets in enhancing LLM performance.","tags":["Computer science","Large language models","Evaluation","Natural language processing","Deep Learning"],"title":"Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models","type":"publication"},{"authors":["Nhi Ngoc Truong","Duc Q. Nguyen","Jeffrey Gropp","Sang T. Truong"],"categories":["Deep Learning"],"content":"","date":1715385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715385600,"objectID":"8d222134b182407c356cd84c3f8398da","permalink":"https://martinakaduc.github.io/publication/hybrid-transformer-and-holt-winter/","publishdate":"2024-05-11T00:00:00Z","relpermalink":"/publication/hybrid-transformer-and-holt-winter/","section":"publication","summary":"Time series forecasting is an important research topic in machine learning due to  its  prevalence  in  social  and  scientific  applications.  Multi-model  forecasting paradigm, including model hybridization and model combination, is shown to be more effective than single-model forecasting in the M4 competition. In this study, we hybridize exponential smoothing with transformer architecture to capture both levels and seasonal patterns while exploiting the complex non-linear trend in timeseries data. We show that our model can capture complex trends and seasonal patterns with moderately improvement in comparison to the state-of-the-arts results from the M4 competition.","tags":["Applied mathematics","Bioinformatics","Computational models","Computational science","Computer science","Disease modeling","Deep Learning","Public health","Time series"],"title":"Hybrid Transformer and Holt-Winter's Method for Time Series Forecasting","type":"publication"},{"authors":["Hoang Nhat Khang Vo","Duc Dong Le","Tran Minh Dat Phan","Tan Sang Nguyen","Quoc Nguyen Pham","Ngoc Oanh Tran","Duc Q. Nguyen","Tran Minh Hieu Vo","Tho Quan"],"categories":["Deep Learning"],"content":"","date":1711238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711238400,"objectID":"9cc0982f23137c48d52dc1ddcfc27f23","permalink":"https://martinakaduc.github.io/publication/revitalizing-bahnaric-language-through-neural-machine-translation/","publishdate":"2024-03-24T00:00:00Z","relpermalink":"/publication/revitalizing-bahnaric-language-through-neural-machine-translation/","section":"publication","summary":"The Bahnar, a minority ethnic group in Vietnam with ancient roots, hold a language of deep cultural and historical significance. The government is prioritizing the preservation and dissemination of Bahnar language through online availability and cross-generational communication. Recent AI advances, including Neural Machine Translation (NMT), have transformed translation with improved accuracy and fluency, fostering language revitalization through learning, communication, and documentation. In particular, NMT enhances accessibility for Bahnar language speakers, making information and content more available. However, translating Vietnamese to Bahnar language faces practical hurdles due to resource limitations, particularly in the case of Bahnar language as an extremely low-resource language. These challenges encompass data scarcity, vocabulary constraints, and a lack of fine-tuning data. To address these, we propose transfer learning from selected pre-trained models to optimize translation quality and computational efficiency, capitalizing on linguistic similarities between Vietnamese and Bahnar language. Concurrently, we apply tailored augmentation strategies to adapt machine translation for the Vietnamese-Bahnar language context. Our approach is validated through superior results on bilingual Vietnamese-Bahnar language datasets when compared to baseline models. By tackling translation challenges, we help revitalize Bahnar language, ensuring information flows freely and the language thrives.","tags":["Computer science","Natural language processing","Neural machine translation","Low-resource language","Transfer learning","Augmentation","Bahnar language"],"title":"Revitalizing Bahnaric Language through Neural Machine Translation:Challenges, Strategies, and Promising Outcomes","type":"publication"},{"authors":["Duc Q. Nguyen"],"categories":["Deep Learning","Natural Language Processing"],"content":"üåü Breaking Ground in Vietnamese Language Models! üåü\nWe are thrilled to unveil our latest advancements in language modeling tailored specifically for the Vietnamese community! üáªüá≥ Get ready to meet our newest members:\nüîπ MixSUra: Harnessing the power of Mixtral, the pioneering MoE (Mixture of Experts) LLM for Vietnamese, MixSUra is set to revolutionize natural language processing with its unparalleled capabilities.\nüîπ GemSUra 7B, 2B: Developed based on Google‚Äôs Gemma 7B, 2B models, GemSUra boasts an extensive vocabulary and precision-engineered algorithms, promising an exceptional linguistic experience like never before.\nBut here‚Äôs where it gets even more exciting! üöÄ We‚Äôre not just stopping at language. We‚Äôre integrating cutting-edge vision-enabled capabilities into our models, creating a seamless fusion of language and image understanding. Introducing:\nüî∏ MixSUraV üî∏ GemSUraV 7B, 2B\nBy incorporating the innovative LLaVA architecture, these models redefine the boundaries of AI by not only understanding language but also interpreting visual data, opening up endless possibilities for applications across various domains.\nGet ready to embark on a journey of unparalleled AI excellence! Stay tuned for the official release, and join us as we pave the way for a new era of language modeling.\n#VietnameseLLM #AIInnovation #LanguageModeling #VietnameseLanguage #MixSUra #GemSUra #LLaVAArchitecture\nüåêüì≤‚ú® MixSUra family: ‚Äã‚Äãhttps://huggingface.co/collections/ura-hcmut/mixsura-65d6fae4fc2da9f5bdf59a79 GemSUra family: https://huggingface.co/collections/ura-hcmut/gemsura-65da96cd27be2e8c65f17131 GemSUra-7B Chatbot: https://www.ura.hcmut.edu.vn/gemsura-chat/\n","date":1710238210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710238210,"objectID":"c68e480912c9b62c615a6402c9421180","permalink":"https://martinakaduc.github.io/post/mixsura-gemsura/","publishdate":"2024-03-12T10:10:10Z","relpermalink":"/post/mixsura-gemsura/","section":"post","summary":"Revolutionizing natural language processing with MixSUra and GemSUra, our latest Vietnamese language models.","tags":["Academic","Large Language Models","Vietnamese","MixSUra","GemSUra"],"title":"Breaking Ground in Vietnamese Language Models","type":"post"},{"authors":null,"categories":null,"content":"Recently, large language models have achieved state-of-the-art results on many natural language processing tasks. It is believed that large language models can learn the knowledge of the world from the text data. As the era of AGI (Artificial General Intelligence) is coming, large language models are considered as one of the key technologies to achieve AGI. In this project, I am interested in developing new large language models and applying them to solve real-world problems.\n","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"ab7a5d83dd835907a54f7f5554e88de3","permalink":"https://martinakaduc.github.io/project/large_language_models/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/project/large_language_models/","section":"project","summary":"Large language models have achieved state-of-the-art results on many natural language processing tasks. I am interested in developing new large language models and applying them to solve real-world problems.","tags":["Deep Learning","Natural Language Processing"],"title":"Large Language Models and Applications","type":"project"},{"authors":null,"categories":null,"content":"Graph theory is a branch of mathematics that studies graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices (also called nodes or points) which are connected by edges (also called links or lines). A graph can be directed or undirected, weighted or unweighted. Graphs are one of the prime objects of study in discrete mathematics.\nProblems in graph theory include graph or subgraph isomorphism, finding the largest clique in a graph, finding the chromatic number of a graph, finding the shortest path between two vertices, finding the minimum spanning tree of a graph, finding the maximum flow in a graph, etc. Currently, existing classical algorithms can solve these problems effectively. However, these algorithms are not scalable and cannot be applied to large-scaled graphs. In this project, I will explore how to use Deep Learning to solve graph theory problems with targeted large-scaled graphs and applications in drug discovery, social network analysis, etc.\nMaster‚Äôs Thesis My Master‚Äôs thesis focuses on enhancing subgraph isomorphism prediction models to improve scalability and interpretability, particularly for applications in drug design. I introduce xNeuSM, an Explainable Neural Subgraph Matching framework, which leverages Graph Learnable Multi-hop Attention Networks (GLeMA) to dynamically learn attention decay parameters across multiple hops. This approach eliminates reliance on fixed hyperparameters and provides theoretical guarantees on approximation errors. Empirical results on real-world datasets show that xNeuSM has higher accuracy than approximate baselines while achieving query times at least seven times faster than exact algorithms. These advancements make subgraph matching more practical for large-scale molecular analysis in drug discovery.\nMaster‚Äôs thesis PDF: Link\nMaster‚Äôs thesis presentation: Link\nMaster‚Äôs thesis code: Link\nPublications Duc Q. Nguyen, et al. ‚Äú10X Faster Subgraph Matching: Dual Matching Networks with Interleaved Diffusion Attention‚Äù, In Proceedings of 2023 International Joint Conference on Neural Networks (IJCNN), 2023. [PDF] [Code] Duc Q. Nguyen, et al., ‚ÄúExplainable Neural Subgraph Matching With Learnable Multi-Hop Attention,‚Äù IEEE Access, vol. 12, pp. 130474‚Äì130492, 2024. [PDF] [Code] ","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"0e0fc10694f76825b800d62fecf31165","permalink":"https://martinakaduc.github.io/project/graph_theory/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/project/graph_theory/","section":"project","summary":"Graph is a powerful data structure that can be used to model many real-world problems. In this project, I will explore how to use Deep Learning to solve graph theory problems.","tags":["Deep Learning","Graph Theory","Graph Representation Learning"],"title":"Solving Graph Theory Problems","type":"project"},{"authors":["Tho Quan Thanh","Giang Dinh Lu","Duc Q. Nguyen","Hai Vu Hoang","Quy Nguyen Tran","Khoa Tran Ngoc Dang","Minh Tran Duy"],"categories":["Deep Learning","Natural Language Processing"],"content":"","date":1701302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701302400,"objectID":"1b6230fe0a81329b85356aa86ad89440","permalink":"https://martinakaduc.github.io/publication/banava-a-cross-platform-ai-mobile-application-for-preserving-the-bahnaric-languages/","publishdate":"2023-11-30T00:00:00Z","relpermalink":"/publication/banava-a-cross-platform-ai-mobile-application-for-preserving-the-bahnaric-languages/","section":"publication","summary":"","tags":["Natural Language Processing","Low-resource Language"],"title":"BaNaVA: A cross-platform AI mobile application for preserving the Bahnaric languages","type":"publication"},{"authors":["Giang Dinh Lu","Hai Vu Hoang","Tho Quan Thanh","Duc Q. Nguyen","Quy Nguyen Tran"],"categories":["Deep Learning","Natural Language Processing",["Speech Processing"]],"content":"","date":1701302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701302400,"objectID":"d21189cddb0e87c8dbe65b372231fd7a","permalink":"https://martinakaduc.github.io/publication/unlocking-the-potential-an-evaluation-of-text-to-speech-models-for-the-bahnar-language/","publishdate":"2023-11-30T00:00:00Z","relpermalink":"/publication/unlocking-the-potential-an-evaluation-of-text-to-speech-models-for-the-bahnar-language/","section":"publication","summary":"","tags":["Natural Language Processing","Speech Processing","Low-resource Language"],"title":"Unlocking the Potential: an evaluation of Text-to-Speech Models for the Bahnar Language","type":"publication"},{"authors":["Hoang-Danh Nguyen","Thanh-Phong To","Duc Q. Nguyen","Thanh-Trung Huynh","Tham Tran","Cong-Tuan Bui","Tho Quan"],"categories":["Deep Learning","Graph Representation Learning"],"content":"","date":1698710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698710400,"objectID":"42b50066b9b9f952423eeee993505ac9","permalink":"https://martinakaduc.github.io/publication/a-novel-approach-for-non-query-fake-news-detection-using-k-som-and-graph-neural-networks/","publishdate":"2023-10-31T00:00:00Z","relpermalink":"/publication/a-novel-approach-for-non-query-fake-news-detection-using-k-som-and-graph-neural-networks/","section":"publication","summary":"The widespread use of social networks has led to an increase in the number of users and posts on these platforms. However, the proliferation of fake news, particularly in the healthcare sector due to the COVID-19 pandemic, has become a significant concern. This has become a significant concern as accepting such fake news can have severe consequences on the health and lives of those who are exposed to it, leading to con- fusion, social disorder, and reputational damage for individuals, organizations, and businesses. Therefore, the automatic detection of fake news on social networks is of utmost importance. In this study, we propose the FANSOG model, which utilizes K-SOM to cluster articles and a graph-based model to automatically detect non-query fake news. Our findings demonstrate that the FANSOG model outperforms other state-of-the-art models in the same research direction.","tags":["Graph Neural Network","Natural Language Processing","COVID-19"],"title":"A novel approach for non-query fake news detection using K-SOM and Graph Neural Networks","type":"publication"},{"authors":["Hoang-Dung Nguyen","Duc Q. Nguyen","Cong-Duy Nguyen","Phong T. To","Danh H. Nguyen","Huy Nguyen-Gia","Long H. Tran","Anh Q. Tran","An Dang-Hieu","Anh Nguyen-Duc","Tho Quan"],"categories":["Deep Learning","Natural Language Processing","Graph Representation Learning"],"content":"","date":1698710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698710400,"objectID":"d26eb1c6f6802fd3cced30e111dd34ca","permalink":"https://martinakaduc.github.io/publication/supervised-learning-models-for-social-bot-detection-literature-review-and-benchmark/","publishdate":"2023-10-31T00:00:00Z","relpermalink":"/publication/supervised-learning-models-for-social-bot-detection-literature-review-and-benchmark/","section":"publication","summary":"Over the past decades, online social networks such as Twitter and Facebook have become a significant part of people‚Äôs daily lives, particularly amid the ongoing global calamity ‚Äî the COVID-19 pandemic. This gives room for social bot attacks that are designed to automatically replicate the behavior of real accounts. Most of these bots are employed for nefarious purposes such as disseminating false information, artificially amplifying the popularity of a person or movement, or spreading spam. Many studies have been conducted in an attempt to discover new strategies for identifying social bot accounts. To deal with large-scale attacks from social bots, Machine Learning has emerged as a noticeable path of bot detection problem that can handle massive amounts of data. However, the heterogeneity between studies in terms of problem statements, proposed processes, datasets, and evaluation metrics makes it difficult to assess and compare the efficiency of proposed methods. In this paper, we propose a systematic view of supervised learning methodologies for tweet-based social bot detection, ranging from shallow learning to specific deep learning models. In addition, we introduce a framework that measures various performance aspects and summarizes the in-depth analysis of the results, which were obtained using two datasets comprising 26224 labeled Twitter accounts. The results of this framework, we believe, will be beneficial as a practical guideline for other bot detection research or applications that require the use of machine learning techniques.","tags":["Natural Language Processing","Graph Neural Network"],"title":"Supervised Learning Models for Social Bot Detection: Literature review and benchmark","type":"publication"},{"authors":["Duc Q. Nguyen"],"categories":["Deep Learning","Natural Language Processing"],"content":"Hello everyone,\nAs a research team formed from members in Ho Chi Minh City University of Technology (HCMUT) - VNU-HCM and Stanford University, we are pleased to introduce our large language models to the community. We affectionately refer to those language models as URA-LLaMa. They are fine-tuned on Vietnamese datasets from Meta‚Äôs original LLaMa-2 model, including all three versions of 7B, 13B, and 70B.\nWe provide these models free of charge for research purposes. Our models come with evaluation results on 10 different tasks, covering various aspects and real-world usage scenarios. You can find information about our models at the following links:\nURA-LLaMa 7B: https://huggingface.co/ura-hcmut/ura-llama-7b URA-LLaMa 13B: https://huggingface.co/ura-hcmut/ura-llama-13b URA-LLaMa 70B: https://huggingface.co/ura-hcmut/ura-llama-70b License and User Agreement: https://github.com/martinakaduc/ura-llama-public/blob/main/URA-LLaMa%20Model%20User%20Agreement.pdf Playground for URA-LLaMa 7B: https://huggingface.co/spaces/ura-hcmut/ura-llama-playground URA-LLaMa Evaluation Results (Actively updating): https://huggingface.co/spaces/ura-hcmut/ura-llama-evaluation\\\nIf you want to contribute to the development of large language models for Vietnamese, please do not hesitate to contact us using the information below.\nAbout the research group:\nWebsite: https://www.ura.hcmut.edu.vn\nEmail: qttho dot hcmut dot edu dot vn\nAbout the model licenses: nqduc at hcmut dot edu dot vn (CC sttruong at cs dot stanford dot edu; qttho at hcmut dot edu dot vn)\nThank you all.\n","date":1696932610,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696932610,"objectID":"601add70d1a23598605fd67a47ec34ff","permalink":"https://martinakaduc.github.io/post/ura-llama-announcement/","publishdate":"2023-10-10T10:10:10Z","relpermalink":"/post/ura-llama-announcement/","section":"post","summary":"First release of URA-LLaMa, a series of large language models for Vietnamese.","tags":["Academic","Large Language Models","Vietnamese","URA-LLaMa"],"title":"URA-LLaMa","type":"post"},{"authors":["La Cam Huy","Le Quang Minh","Tran Ngoc Oanh","Le Duc Dong","Duc Q. Nguyen","Nguyen Tan Sang","Tran Quan","Tho Quan"],"categories":["Deep Learning","Natural Language Processing"],"content":"","date":1696032e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696032e3,"objectID":"fe5890cb26ed73096063ad88151485b2","permalink":"https://martinakaduc.github.io/publication/low-rank-adaptation-approach-for-vietnamese-bahnaric-lexical-mapping-from-non-parallel-corpora/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/low-rank-adaptation-approach-for-vietnamese-bahnaric-lexical-mapping-from-non-parallel-corpora/","section":"publication","summary":"","tags":["Natural Language Processing","Low-resource Language"],"title":"Low-Rank Adaptation Approach for Vietnamese-Bahnaric Lexical Mapping from Non-Parallel Corpora","type":"publication"},{"authors":["Dang Tran Dat","Tang Quoc Thai","Duc Q. Nguyen","Vo Duy Hung","Quan Thanh Tho"],"categories":["Deep Learning","Speech Processing"],"content":"","date":1696032e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696032e3,"objectID":"6e84a20c9c1677a175445ee26e513f0b","permalink":"https://martinakaduc.github.io/publication/voice-conversion-for-natural-sounding-speech-generation-on-low-resource-languages-a-case-study-of-bahnaric/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/voice-conversion-for-natural-sounding-speech-generation-on-low-resource-languages-a-case-study-of-bahnaric/","section":"publication","summary":"","tags":["Speech Processing","Low-resource Language"],"title":"Voice Conversion for Natural-Sounding Speech Generation on Low-Resource Languages: A Case Study of Bahnaric","type":"publication"},{"authors":["Sang T. Truong","Duc Q. Nguyen","Tho Quan","Sanmi Koyejo"],"categories":["Deep Learning","Reinforcement Learning"],"content":"","date":1690761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690761600,"objectID":"dbad4e8b3a7a395d0b65edbf9d60bc38","permalink":"https://martinakaduc.github.io/publication/thomas-learning-to-explore-human-preference-via-probabilistic-reward-model/","publishdate":"2023-07-31T00:00:00Z","relpermalink":"/publication/thomas-learning-to-explore-human-preference-via-probabilistic-reward-model/","section":"publication","summary":"Recent breakthroughs in large language models and multimodal models underscore the impressive strides deep learning has made in tackling sophisticated tasks previously deemed achievable solely by humans. In particular, discerning human thoughts or interests via communication and feedback is garnering attention for its potential to enable machines to provide insightful responses or recommendations. Nonetheless, despite progressive developments, preference learning from human feedback is hindered by poor sample complexity, as it primarily employs preferred responses for tuning, consequently failing to holistically capture user preferences. Moreover, it is imperative to ensure diversity in the responses generated, as this diversity is instrumental in enabling users to ascertain their genuine preferences, which in turn, is conducive to the fine-tuning of the response generation model. In this study, we introduce a novel method known as Thomas, which utilizes Bayesian neural networks for capturing user preferences, and Thompson sampling to enhance the exploration ability of the response generation model. This synergy ensures alignment of generated responses with user preferences, while preserving diversity, thus expediting the learning process. Experimental evaluations in synthetic environments affirm the proficiency of our method in swiftly adapting to user preferences and generating increasingly favored responses.","tags":["Human-in-the-loop","Reinforcement Learning","Preference-based Learning"],"title":"Thomas: Learning to Explore Human Preference via Probabilistic Reward Model","type":"publication"},{"authors":["Thanh Toan Nguyen","Duc Q. Nguyen","Zhao Ren","Jun Jo","Quoc Viet Hung Nguyen","Thanh Tam Nguyen"],"categories":["Deep Learning","Graph Representation Learning"],"content":"","date":1687081294,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687081294,"objectID":"3ca81ae149aba4d6c46452ac1d32188f","permalink":"https://martinakaduc.github.io/publication/10x-faster-subgraph-matching-dual-matching-networks-with-interleaved-diffusion-attention/","publishdate":"2023-06-18T09:41:34.35Z","relpermalink":"/publication/10x-faster-subgraph-matching-dual-matching-networks-with-interleaved-diffusion-attention/","section":"publication","summary":"The goal of subgraph matching is to determine the presence of a particular query pattern within a large collection of data graphs. Despite being a hard problem, subgraph matching is essential in various disciplines, including bioinformatics, text matching, and graph retrieval. Although traditional approaches could provide exact solutions, their computations are known to be NP-complete, leading to an overwhelmingly querying latency. While recent neural-based approaches have been shown to improve the response time, the oversimplified assumption of the first-order network may neglect the generalisability of fully capturing patterns in varying sizes, causing the performance to drop significantly in datasets in various domains. To overcome these limitations, this paper proposes xDualSM, a dual matching neural network model with interleaved diffusion attention. Specifically, we first embed the structural information of graphs into different adjacency matrices, which explicitly capture the intra-graph and cross-graph structures between the query pattern and the target graph. Then, we introduce a dual matching network with interleaved diffusion attention to carefully capture intra-graph and cross-graph information while reducing computational complexity. Empirically, our proposed framework not only boosted the speed of subgraph matching more than 10√ó compared to the fastest baseline but also achieved significant improvements of 47.64% in Recall and 34.39% in F1-score compared to the state-of-the-art approximation approach on COX2 dataset. In addition, our results are comparable with exact methods.","tags":["Graph Neural Network","Subgraph Isomorphism","Artificial Intelligence"],"title":"10X Faster Subgraph Matching: Dual Matching Networks with Interleaved Diffusion Attention","type":"publication"},{"authors":["Hoang-Dung Nguyen","Duc Q. Nguyen","Hao Luong Pham","Tho Thanh Quan"],"categories":["Deep Learning","Graph Representation Learning"],"content":"","date":1687076269,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687076269,"objectID":"620ec7dace80711b8684693d12efe0ac","permalink":"https://martinakaduc.github.io/publication/social-bot-detector-using-graph-neural-networks/","publishdate":"2023-06-18T08:17:49.839Z","relpermalink":"/publication/social-bot-detector-using-graph-neural-networks/","section":"publication","summary":"The importance of online social networks (OSNs) has been fueled by the human need for digital communication and broadcasting, as well as the improved state of internet connections and electronic devices. Meanwhile, social bots have been designed to automatically replicate the behavior of legitimate users in order to manipulate these OSNs. As a result, social bot detectors have been conducted concurrently, mostly on Twitter, in an attempt to discover new strategies for countering social bot attacks. In this paper, we propose SOBOG, a deep learning architecture that takes tweet relations, tweet semantics, and user properties into account to perform account-level and tweet-level detection. SOBOG also achieves outstanding performance on both tasks.","tags":["Graph Neural Network","Artificial Intelligence","Social Bot Detection"],"title":"Social Bot Detector using Graph Neural Networks","type":"publication"},{"authors":["Duc Q. Nguyen"],"categories":null,"content":"Please join the meeting using the link above.\nHere is the playground notebook for the talk: Colab Notebook\n","date":1677924e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677924e3,"objectID":"bb4c51e5a683d68332b1e373132f0f35","permalink":"https://martinakaduc.github.io/talk/diffusion-models-from-theory-to-experiments/","publishdate":"2023-03-03T08:00:00Z","relpermalink":"/talk/diffusion-models-from-theory-to-experiments/","section":"event","summary":"A talk on diffusion models and their applications in computer vision.","tags":["Diffusion Models","Deep Learning","Computer Vision"],"title":"Diffusion models: From Theory to Experiments","type":"event"},{"authors":["Duc Q. Nguyen"],"categories":["Bayesian Statistics","Deep Learning","Artificial Intelligence"],"content":"Today marks the 7th anniversary of their relationship‚Ä¶. The young man is very excited because today he has meticulously prepared to propose to the girl. There are 99 roses, candles, an engagement ring, and even a perfect script to make today one of the most significant days of his life. He practiced singing the song ‚ÄúBecause It‚Äôs You‚Äù hundreds, if not thousands, of times, hoping to create a surprise for the girl. The once determined and aspiring young man has now grown into an accomplished researcher, becoming more mature with each passing day.\nAs for the girl, a daughter of Saigon, she has always been the center of attention for many young men. Not only for her beauty and charming demeanor but also because she is one of the top students in her department. Back then, she chose to love him at the beginning of their first year at university, simply because he was a good person with ambition. Since loving him, she has discovered many flaws in herself and has strived to improve.\nThroughout the month, she noticed that he seemed mysterious, often going somewhere or disappearing for hours. Despite her attempts to inquire, he only responded vaguely. ‚ÄúThere must be a problem!‚Äù she thought. However, with nearly 7 years of love and absolute trust, she simply believed that he might be facing some difficult issues. If it were another woman, she would have made a fuss and investigated thoroughly, but she wasn‚Äôt like that. It was one of the qualities the young man liked most about her ‚Äì calm and warm instead of noisy and chaotic.\nFinally, today has arrived. He arrives to pick her up an hour earlier than scheduled, breaking the norm. With meticulously chosen attire ‚Äì a light yellow long-sleeved shirt, black trousers, and dark brown leather high-top shoes ‚Äì he looks like a prince stepping out of a French-style grand castle. In his hand, he holds a bouquet of roses to kick off this special day. As for the girl, she chooses a moderately short sky-blue dress with puffed sleeves reminiscent of Disney princess dresses. A light green bow complements her outfit. She does her makeup in a light, everyday style before leaving her room and descending the stairs. She sees him waiting with the rose bouquet in hand. ‚ÄúDamn! What is he up to?‚Äù she thinks to herself. He hands her a flower and then takes her on the Cup50, their companion throughout the years, for a tour around the city ‚Äì from the book street to Ben Thanh Market and finally stopping at a riverside caf√© in Saigon.\nAs usual, he orders a hot cappuccino while she opts for a cool cocktail, a choice often made by independent-minded girls. Glancing across the street, she notices a flower vendor selling Valentine‚Äôs Day flowers, with one large rose standing out in the middle. ‚ÄúCertainly, any girl who receives that rose will be very happy,‚Äù she says, pointing towards the rose. The young man smiles knowingly, understanding that everything is part of his plan. ‚ÄúYou think so?‚Äù he replies after taking a sip of his coffee. ‚ÄúI don‚Äôt know, but the probability is very high,‚Äù she responds. ‚ÄúWell, stop daydreaming, silly.‚Äù She doesn‚Äôt answer because she knows he isn‚Äôt the romantic type; in reality, scientists prefer simplicity. Suddenly, an argument breaks out in the caf√© between a couple, and they both turn to look. Above, near the screen playing the caf√©‚Äôs favorite music, another couple stands out. The argument gets louder, and the young man suggests helping them. At that moment, the other man raises his hand, seemingly ready to physically intervene with the woman. Some people rush to intervene. The young man seems to disappear from the girl‚Äôs sight in the crowd. She tries to stand up to see where her boyfriend is, and the man says, ‚ÄúIf you‚Äôre good, look at the screen.‚Äù Hearing that, she becomes somewhat puzzled, not knowing what will happen. Suddenly, the familiar notes of the song ‚ÄúBecause It‚Äôs You‚Äù begin playing. The screen starts showing images of her, him, and the happy moments they‚Äôve shared over the past 7 years. Her heart rate exceeds 140 bpm, and the adrenaline level in her blood doubles. She doesn‚Äôt know what to do, just standing there, tears streaming down her face. People in the caf√© begin to move aside, creating an atmosphere as if they are anticipating something special.\nHolding a carefully crafted bouquet of 99 roses, he walks towards her, singing their love song. Approaching her, he opens the ring box attached to the rose bouquet, kneels down beside her, and says, ‚ÄúThank you for choosing me and being with me for the past 7 years. We‚Äôve experienced many ups and downs in life, and I‚Äôm grateful to always have you by my side, supporting and sharing the joys and sorrows. Today is a special day for all couples in love, and it‚Äôs also a very special day for us. Here, in this moment, I hope you give me the opportunity to complete the 100th rose in this bouquet and to become an indispensable part of your life from now on.‚Äù ‚ÄúDamn, what kind of emotion is this?‚Äù she says, both touched and ‚Ä¶","date":1676369410,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676369410,"objectID":"39dd8b9bea93ff4161ea8f89f2d0c111","permalink":"https://martinakaduc.github.io/post/valentine-day/","publishdate":"2023-02-14T10:10:10Z","relpermalink":"/post/valentine-day/","section":"post","summary":"A story about a young researcher preparing to propose to his girlfriend.","tags":["Love","Life","Story","Bayesian Optimization","Deep Learning"],"title":"The Valentine's Day Story.","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"SAVING THE DAY‚Ä¶\nUniversity is like a bus stop in front of the school gate. Get on, go, and then come back, starting a new semester again. Get on, go and never come back, then graduate‚Ä¶\nThe four-year journey with Bach Khoa in the role of a student has officially come to an end for me. Four years of youth, four years dedicated to Bach Khoa, more specifically, the months and days spent facing tight deadlines with comrades, friends, the moments of joy when receiving scholarships, and also the sorrows of losing a few things.\nToday, wearing the graduation gown, I believes that this is not just my own effort but also depends heavily on the care of family, the guidance of teachers, the support of siblings and friends, and the uncles and aunts within the relationships. And truly, there are no words to fully express, and no book can capture all the love that everyone has given to me.\nTherefore, on this occasion, I would like to express the most sincere gratitude to everyone who has helped and supported him throughout the challenging journey of growth.\nI hopes to continue receiving love and trust from everyone and to accompany everyone in the upcoming journey full of ups and downs and challenges.\nSincerely,\nEngineer Nguy·ªÖn Quang ƒê·ª©c\n22:11 on November 22, 2022\n","date":1669155060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669155060,"objectID":"5fd2219deb3e0a0652680b37b296fa59","permalink":"https://martinakaduc.github.io/post/bachelor-graduation/","publishdate":"2022-11-22T22:11:00Z","relpermalink":"/post/bachelor-graduation/","section":"post","summary":"Some words for the graduation day","tags":["Personal","Life"],"title":"Bachelor Graduation","type":"post"},{"authors":null,"categories":null,"content":"Drug discovery is a complex, expensive, and time-consuming process. It involves the identification of a target, screening of a large number of molecules, and optimization of the selected molecules. The process of drug discovery can be accelerated by using machine learning and deep learning. I am interested in solving problems in drug discovery using deep learning. I am also interested in developing new deep learning models for drug discovery.\nGraduate Thesis My graduate thesis was on the application of deep learning to drug discovery. I worked on the the problem of building pharmacophore model for a given molecule (COVID-19 Mpro). The pharmacophore model of a molecule is a set of points in 3D space that represent the important features of the molecule. The pharmacophore model is used to screen a large number of molecules to find the molecules that are promising candidates for drug discovery. I used a deep learning model to build the pharmacophore model of a molecule. My approach contains following steps:\nUsing a deep learning model to predict the binding affinity of a molecule to a target protein (Mpro). Using the predicted binding affinity to find the binding site of the molecule on the target protein. Using the binding site to build the pharmacophore model of the molecule. Using the pharmacophore model to screen a large number of molecules to find the molecules that are promising candidates for drug discovery and build a recommender system for drug discovery. My built system is available at Link.\nAccount: Test\nPassword: test\nOr you can register a new account.\nThesis PDF: Link\nThesis presentation: Link\nThesis code: Link\nPublications Duc Q. Nguyen, et al. ‚ÄúTowards de Novo Drug Design for the Coronavirus: A Drug-Target Interaction Prediction Approach Using Atom-Enhanced Graph Neural Network with Multi-Hop Gating Mechanism‚Äù In Proceedings of 2022 9th Nafosted Conference on Information and Computer Science (2022). Best Paper Award Link ","date":1669075200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669075200,"objectID":"fc2262c4c504e5536102bb9d55afdf20","permalink":"https://martinakaduc.github.io/project/drug_discovery/","publishdate":"2022-11-22T00:00:00Z","relpermalink":"/project/drug_discovery/","section":"project","summary":"Drug discovery is a complex, expensive, and time-consuming process. I am interested in solving problems in drug discovery using deep learning to accelerate the process of drug development.","tags":["Deep Learning","Drug Discovery","Graph Representation Learning","Language Models"],"title":"Drug Discovery","type":"project"},{"authors":["Duc Q. Nguyen","Khoan D. Le","Bach T. Ly","An D. Nguyen","Quang H. Nguyen","Tuan H. Nguyen","Cuong Quoc Duong","Thanh N. Truong","Phuong Thuy Viet Nguyen","Tho T. Quan"],"categories":["Deep Learning","Graph Representation Learning"],"content":"","date":1666595544,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666595544,"objectID":"6d22b33a77f9cd44690d190748a34ff4","permalink":"https://martinakaduc.github.io/publication/towards-de-novo-drug-design-for-the-coronavirus-a-drug-target-interaction-prediction-approach-using-atom-enhanced-graph-neural-network-with-multi-hop-gating-mechanism/","publishdate":"2022-10-24T07:12:24.809Z","relpermalink":"/publication/towards-de-novo-drug-design-for-the-coronavirus-a-drug-target-interaction-prediction-approach-using-atom-enhanced-graph-neural-network-with-multi-hop-gating-mechanism/","section":"publication","summary":"For humans, the COVID-19 pandemic and Coronavirus have undeniably been a nightmare. Although there are effective vaccines, specific drugs are still urgent. Normally, to identify potential drugs, one needs to design and then test interactions between the drug and the virus in an in silico manner for determining candidates. This Drug-Target Interaction (DTI) process, can be done by molecular docking, which is too complicated and time-consuming for manual works. Therefore, it opens room for applying Artificial Intelligence (AI) techniques. In particular, Graph Neural Network (GNN) attracts recent attention since its high suitability for the nature of drug compounds and virus proteins. However, to introduce such a representation well- reflecting biological structures of biological compounds is not a trivial task. Moreover, since available datasets of Coronavirus are still not highly popular, the recently developed GNNs have been suffering from overfitting on them. We then address those issues by proposing a novel model known as Atom-enhanced Graph Neural Network with Multi-hop Gating Mechanism. On one hand, our model can learn more precise features of compounds and proteins. On the other hand, we introduce a new gating mechanism to create better atom representation from non- neighbor information. Once applying transfer learning from very large databanks, our model enjoys promising performance, especially when experimenting with Coronavirus.","tags":["Graph Neural Network","Artificial Intelligence","COVID-19","Drug Discovery","De Novo Drug Design"],"title":"Towards de Novo Drug Design for the Coronavirus: A Drug-Target Interaction Prediction Approach Using Atom-Enhanced Graph Neural Network with Multi-Hop Gating Mechanism","type":"publication"},{"authors":["Duc Q. Nguyen","Nghia Q. Vo","Thinh T. Nguyen","Khuong Nguyen-An","Quang H. Nguyen","Dang N. Tran","Tho T. Quan"],"categories":["Deep Learning"],"content":"","date":1652456313,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652456313,"objectID":"d3de0bbddd8bebd4b8097496fdd06eec","permalink":"https://martinakaduc.github.io/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/","publishdate":"2022-05-13T15:38:33.657Z","relpermalink":"/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/","section":"publication","summary":"From the end of 2019, one of the most serious and largest spread pandemics occurred in Wuhan (China) named *Coronavirus* (COVID-19). As reported by the World Health Organization, there are currently more than 100 million infectious cases with an average mortality rate of about five percent all over the world. To avoid serious consequences on people's lives and the economy, policies and actions need to be suitably made in time. To do that, the authorities need to know the future trend in the development process of this pandemic. This is the reason why forecasting models play an important role in controlling the pandemic situation. However, the behavior of this pandemic is extremely complicated and difficult to be analyzed, so that an effective model is not only considered on accurate forecasting results but also the explainable capability for human experts to take action pro-actively.\n\nWith the recent advancement of *Artificial Intelligence* (AI) techniques, the emerging *Deep Learning* (DL) models have been proving highly effective when forecasting this pandemic future from the huge historical data. However, the main weakness of DL models is lacking the explanation capabilities. To overcome this limitation, we introduce a novel combination of the *Susceptible-Infectious-Recovered-Deceased* (SIRD) compartmental model and *Variational Autoencoder* (VAE) neural network known as BeCaked. With pandemic data provided by the Johns Hopkins University Center for Systems Science and Engineering, our model achieves $0.98$ $R^2$ and $0.012$ $MAPE$ at world level with $31$-step forecast and up to $0.99$ $R^2$ and $0.0026$ $MAPE$ at country level with $15$-step forecast on predicting daily infectious cases. Not only enjoying high accuracy, but BeCaked also offers useful justifications for its results based on the parameters of the SIRD model. Therefore, BeCaked can be used as a reference for authorities or medical experts to make on time right decisions.","tags":["Applied mathematics","Bioinformatics","Computational models","Computational science","Computer science","Differential equations","Disease modeling","Dynamical systems","Machine learning","Deep Learning","Public health","Time series"],"title":"BeCaked: An Explainable Artificial Intelligence Model for COVID-19 Forecasting","type":"publication"},{"authors":["Cuong Nguyen Dang","Minh Nguyen Huynh","Duc Q. Nguyen","Duc Nguyen Quang","Thinh Nguyen Tien","Khuong Nguyen An","Chon Le Trung","Tho Quan Thanh"],"categories":["Deep Learning"],"content":"","date":1650901842,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650901842,"objectID":"b29502b6f080c6dc2970191ea66ec7b0","permalink":"https://martinakaduc.github.io/publication/becaked-an-explainable-ai-model-to-forecast-delta-spreading-covid-19/","publishdate":"2022-04-25T15:50:42.595Z","relpermalink":"/publication/becaked-an-explainable-ai-model-to-forecast-delta-spreading-covid-19/","section":"publication","summary":"Covid-19 is a global disaster which requires not only medical humanity but also computing power to predict, and, ideally, interpret these pandemics. Deep models can be trained to be fairly accurate. However, the mechanism of models prevents from explainability. On the hand, epidemiological approaches, e.g. SIR, help experts with insightful information. However, those need to be provided with parameter values, which become complicated in certain locations.\nThe fourth wave of the pandemic in Ho Chi Minh City (HCMC), Vietnam in 2021 offers valuable lessons along with real and specific data. Hence, we introduce an explainable AI model known as BeCaked+ to predict and analyze efficiently the pandemic situation from the collected data. BeCaked+ combined deep learning and epidemiological models enhanced by specific parameters related to the policies endorsed by the government. Such combination makes BeCaked+ accurate and informative for policymakers to make appropriate responses. One take a try BeCaked+ at [http://www.cse.hcmut.edu.vn/BeCaked](ttp://www.cse.hcmut.edu.vn/BeCaked).","tags":["BeCaked+","Covid-19","Ho Chi Minh City","Delta-variant","Explainable AI","Epidemic mode","Time series","Deep Learning"],"title":"BeCaked+: An Explainable AI Model to Forecast Delta-spreading Covid-19","type":"publication"},{"authors":["Thanh Tam Nguyen","Thanh Toan Nguyen","Thanh Cong Phan","Duc Q. Nguyen","Quoc Viet Hung Nguyen"],"categories":null,"content":"","date":1637767734,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637767734,"objectID":"33fc6ddfa2e63583edd459b239879f71","permalink":"https://martinakaduc.github.io/publication/realtime-bushfire-detection-with-spatial-based-complex-event-processing/","publishdate":"2021-11-24T15:28:54.73Z","relpermalink":"/publication/realtime-bushfire-detection-with-spatial-based-complex-event-processing/","section":"publication","summary":"Bushfire is the primary destructive force that may cause damage to a large region, a country, or even the Earth. However, as bushfires spread too fast, they are often identified when they cannot control and cause significant damage. The reason is that existing works on remote sensing focus on low-level information processing, and thus, face the challenge of processing a massive amount of data in real-time. In this work, we employ complex event processing (CEP) to extract higher-level information to facilitate real-time bushfire detection. In particular, we propose a ‚Äúspatial extension‚Äù to the ready-powerful CEP techniques to enable bushfire monitoring from the combinations of multiple spatial events. We further demonstrate the proposed spatial-based CEP on a real-time bushfire detection problem. Experimental results illustrate that our approach scales well while achieving the competitive detection performance.","tags":["bushfire detection","complex event processing","spatial query"],"title":"Realtime Bushfire Detection with Spatial-based Complex Event Processing","type":"publication"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"Self-learning, perhaps we are already quite familiar with this phrase. It is so widespread that even children who have just learned to read or write, and street vendors on the sidewalks, have likely heard and used it at least once. While each of us may have our own definition of self-learning, in terms of the concept, it can broadly be understood as ‚ÄúSelf - Learning.‚Äù\nSo, what does ‚ÄúSelf‚Äù mean? For me, ‚ÄúSelf‚Äù encompasses several meanings: self-awareness, self-assessment, self-action, and self-pride. Self-awareness allows us to have a consciousness of studying, working on time, following schedules without procrastination or prolonged periods. Self-assessment helps us understand where we are, what position we are in, and how to continue striving scientifically and efficiently. Self-action means that we must take action for ourselves, seek what is necessary and beneficial, and start implementing it. Lastly, self-pride. Once we have gone through self-awareness, self-assessment, self-action, and achieved what we expected, we have the right to take pride in our accomplishments, in what we have, and what we have achieved. Perhaps these results are not perfect in the literal sense, but at least they reflect the process of our hard work, effort, and sweat.\nFollowing ‚ÄúSelf,‚Äù we have ‚ÄúLearning.‚Äù Why is it ‚ÄúLearning‚Äù instead of ‚ÄúStudy,‚Äù or any compound nouns with the word ‚ÄúLearn-‚Äù at the forefront? From my perspective, ‚ÄúLearning‚Äù encompasses both ‚ÄúStudy‚Äù and ‚ÄúPractice.‚Äù During the ‚Äúlearning process,‚Äù we can easily encounter various learning methods: learning by doing (Studying), learning and then practicing applying what was taught (Learning by practice), observing others and learning from them (Learning by observation), ‚Ä¶ But my friend, I am sure that, sooner or later, your learning process will encounter obstacles. And at that moment, I am confident that if you genuinely desire to study seriously from the beginning, you will start fervently seeking solutions to that problem immediately, right? At this point, the knowledge you have accumulated seems to be trapped in a box full of chaos, and what you need most at this time‚Ä¶ ask yourself‚Ä¶ is it ‚Äúhelp‚Äù from someone to connect the chaos in your head? To be straightforward, do these questions and uncertainties become the final barrier preventing you from fully grasping knowledge? ‚Ä¶ For that reason, from my point of view, ‚ÄúLearning‚Äù carries a more serious meaning to help us progress further, to have a deeper understanding of the knowledge we have learned.\nIntegrating both concepts, ‚ÄúSelf‚Äù and ‚ÄúLearning,‚Äù we get a fresher concept, ‚ÄúSelf-learning.‚Äù Based on the evidence presented above, we can easily see that ‚ÄúSelf-learning‚Äù does not mean just focusing on devouring a textbook, doing a bunch of exercises, or forcing yourself to master all the essence of a subject. For me, ‚ÄúSelf-learning‚Äù must be a process of seeking your own learning path. More clearly, ‚ÄúSelf-learning‚Äù will include three steps. First, set for yourself a passion, a specific schedule of achievable goals corresponding to time frames (and of course, this is just an initial estimate). The second step is to follow the established principles. This step is the most difficult, easy to give up, and most easily distorted. However, if you can adhere to the principles set for a long enough time, it will become a habit that helps us have a persistent will and a stronger spirit. In this step, routine tasks will include: finding relevant materials and figuring out how to digest them, testing yourself with exercises, related practical tasks, trying every way to solve problems in your own way. And the final step is when we encounter a problem that we cannot find a solution to, or the solution we come up with does not satisfy us, this is the most appropriate time to seek help from: teachers, parents, friends, experts, blogs, forums, ‚Ä¶ And then‚Ä¶ go back to the second step. With this three-step process, we can easily see that external help is part of the ‚ÄúSelf-learning‚Äù process and does not violate the initial concepts of this process. Quite simply, to get help, we have to ‚ÄúSelf‚Äù seek the right person who can guide us to solve the problem, and ‚ÄúLearning‚Äù learn from their solutions, their way of thinking. In that process, we have to know how to present our issues and know what help we need from them. In summary, self-learning and learning from external help, though two but one, and we cannot deny the individual benefits of each process. If you don‚Äôt self-learn and rely entirely on external help, soon enough, you will become dependent and conform to what is passed down. On the contrary, if you only self-learn without external help, we may fall into arrogance, self-satisfaction, and may lead to distortions in the knowledge acquired. Only when we harmoniously combine these two processes, creating a unified process, can we progress further, have the opportunity to interact, learn from various sources, and enrich our knowledge on our ‚Ä¶","date":1617358210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617358210,"objectID":"af4c744795d78b3bec07374e5a1d5865","permalink":"https://martinakaduc.github.io/post/self-learning/","publishdate":"2021-04-02T10:10:10Z","relpermalink":"/post/self-learning/","section":"post","summary":"Do you know what \"Self-learning\" means?","tags":["Personal","Life"],"title":"Self-learning","type":"post"},{"authors":["Duy Nguyen","Duc Q. Nguyen","Thong Nguyen","Khoi Ngo","Hung Cao","Thinh Vuong","Tho Quan"],"categories":null,"content":"","date":1605798913,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605798913,"objectID":"0376272fc12924f6997cfa140f7c1420","permalink":"https://martinakaduc.github.io/publication/automatic-container-code-recognition-using-multideep-pipeline/","publishdate":"2020-11-19T15:15:13.322Z","relpermalink":"/publication/automatic-container-code-recognition-using-multideep-pipeline/","section":"publication","summary":"Identification of license plates on intermodal containers (or containers) while entering and departing from the yard provides a wide range of practical benefits, such as organizing automatic opening of the rising arm barrier at the entrance and exit to and from the site. In addition, automatic container code recognition can also assist in thwarting the entrance of unauthorized vehicles into the territory. With the recent development of AI, this process is preferably automatic. However, the poor quality of images obtained from surveillance cameras might have detrimental effects on AI models. To deal with this problem, we present a pipeline dubbed as MultiDeep system, which combines several state-of-the-art deep learning models for character recognition and computer vision processes to solve problems of real camera data. We have also compared our results with other pipeline models on real data and accomplished fairly positive results. In this paper, without further references, we will only consider intermodal containers when referring to them as containers.","tags":["container code","optical character recognition","MultiDeep pipeline"],"title":"Automatic Container Code Recognition Using MultiDeep Pipeline","type":"publication"},{"authors":["Duc Q. Nguyen","Thien Cong Pham","Tho Thanh Quan"],"categories":null,"content":"","date":1602946440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602946440,"objectID":"79a3ceb2f8211a74d015ba2ed4cd8013","permalink":"https://martinakaduc.github.io/publication/design-implementation-and-evaluation-for-a-high-precision-prosthetic-hand-using-myoband-and-random-forest-algorithm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/design-implementation-and-evaluation-for-a-high-precision-prosthetic-hand-using-myoband-and-random-forest-algorithm/","section":"publication","summary":"A prosthesis is an equipment provided to people who lost one or some parts of their limbs to help them having almost normal behaviors in daily or hard activities. The convenience and intelligence of devices should create easiness and flexibility for users. Artificial devices require interdisciplinary collaboration from neurosurgeons, surgical surgeons, physiotherapists and equipment development. Computer engineering plays a crucial role in the design step, supporting manufacturing, training and recognition to match the desirability of customers. Moreover, users need a wide range of different options such as an aesthetic functional material, a myoelectric mechanism, a body-powered appliance or an activity specified device. Thus, the flexible configuration, the proper features and the cost are some important factors that drive user's selection to the prosthesis. In this article, we describe an effective and powerful solution for analyzing, designing hardware and implementing software to train and recognize hand gestures for prosthetic arms. Moreover, we provide evaluation data of the method compared with similar approaches to support our design and implementation. This is fairly a complete system, making it a convenient solution for hand-cutoff people to control prosthetic hands using their electromyography signals. Statistical results with evaluations show that the device can respond correspondingly and the method creates promisingly recognition data after correct training processes. The prosthetic hardware implementation has also been simulated using a Light-emitting diode (LED) hand model with a high accuracy result.","tags":["machine learning","random forest","prosthetic hand","electromyography"],"title":"Design, implementation and evaluation for a high precision prosthetic hand using MyoBand and Random Forest algorithm","type":"publication"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"Each of us was born and grow up by the laws of nature that no one can resist. In such a long and arduous journey, there must be many times we certainly face some traumas from this life. Perhaps they are falls, scars by carelessness, or the words and actions of others that immerse us in the despair about ourselves. On the path to becoming a true adult, we are continuously looking for solutions and answers for past traumas; but unintentionally, we hurt others. Others here are not strangers, they can be our families, friends, lovers, colleagues‚Ä¶ And thus, the injuries have not been healed, but increasingly spread out. This makes the growing-up journey more and more difficult. But anyway, you still have to grow up and find the right answer for your own life.\nI have heard a quote like this ‚ÄúStrength of a person is shaped in his own weakness\u0026#34;. I don‚Äôt know what you think, but to me, growing up is a ‚Äúthorn‚Äù. Why? I will tell you stories that you may have been the protagonists of:\nYou saw a dog growling, your mother tells you to stay away from it and draw scary scenes. So, you are afraid of dogs üôÇ You asked to study an art subject that you like, but your family objected. And then your family praises another child with that talent. The neighbor kid dropped in and took or broke an item that you like so much. And adults say it was okay. Parents often say that you are lazy to exercise. But every time go out of the house for a little bit long, sure to hear their complaints. You absolutely don‚Äôt like that boring math, but you must learn because 3 generations of your family are excellent doctors. You are bullied by older children, but can‚Äôt tell anyone. Not because you don‚Äôt want to say it, but because you know that you‚Äôll receive apologies at the most. You are too gentle! Everyone expects you to pass that exam, but your result is not as expected even though you try your best. And people think that you have not tried enough although your learning conditions are far behind those who luckily pass. The harsh truth is that there is no way to grow in sweetness. Growth is a path full of roses, but every rose has its thorns, the thorn is small but can tear all the courage in you, enough to make you fall, make you extremely disappointed. But you have to stand up and move on your own feet, heal the scratches printed for years in the depths of your soul. Only having passed by yourself, you can feel the beauty and sweet scent on each red rose petal, which is also what build up you at the present. The red color of flowers is your own sweat, tears and blood. It is the most practical evidence for the efforts you made to stand here today.\nDo you know? One of the things that makes people more mature is a broken love. Even if today you cry your eyes out for someone who doesn‚Äôt love you, the next day you still have to have a bright smile to welcome the sunrise. Because maturity is when you learn to love yourself. For a caterpillar, becoming a butterfly means going through extremely painful cocoons and molting. But after all, the used-to-be-ugly caterpillar has become a beautiful butterfly with all patterns on the wings. Can you see, in order to grow up, humans as well as caterpillar have to suffer pain and hurt to find a way to heal themselves.\nThe fine line between children and adults is maturity. You can choose to be a child because children only have to eat, play, study and sleep. Adults are a somewhat better version than children because they have been battered many times, and after each fall, they stand up and move on, try to reach their goal on the chosen path. So adults may have a stronger mind, be able to make their own dreams come true - something that children cannot.\nAlthough growing up means suffering, if not experiencing, an adult is just a child in an ageing body - an incomplete adult. Perhaps because maturity is a thorn that everyone gets at least one stab. But when you are young, any wound will be easier to heal, enthusiasm of life is brimful so you can stand up and go straight, youth is the brightest, wildest, most beautiful fire. It can be extinguished many times, but after each suppression it will flare up stronger.\nWe all know that traumas belong to individuals, but we can spread from person to person. For example, today your boss is unhappy because he just broke up with his girlfriend, and later unreasonable scolded you, although your report is very good. Then, you go home, because of that little frustration, you take it out on your family. In the end, your happiness cracked again. Do you see? Trauma though is not a serious infectious disease like COVID-2019, it also spreads very quickly and the consequences are also not so mild. Therefore, my buddies, if you are experiencing such situations, please have the most generous and sympathetic heart to understand and forgive them, don‚Äôt let yourself become a source of infection to others, it only makes you more deeply vulnerable.\nThe Creator always gives people the good ‚Ä¶","date":1583662210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583662210,"objectID":"73c37b933d9745cdee7a470a9f34f403","permalink":"https://martinakaduc.github.io/post/for-growing-us/","publishdate":"2020-03-08T10:10:10Z","relpermalink":"/post/for-growing-us/","section":"post","summary":"The way to grow up is not easy, but it is the only way to find the right answer for your own life.","tags":["Personal","Life"],"title":"For growing us","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"By the time you realize that all the ‚Äúmore‚Äù in the world are just differences, there is no inferiority in level, able to live with what you like, and if you like something you will try to have it, not because anyone has it, but because you need it, that‚Äôs the time when you cross the line of envy and live your own life.\nCredit: OOPSY\n","date":1579255810,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579255810,"objectID":"2f64fd9688345907a381ec6dab5134b0","permalink":"https://martinakaduc.github.io/post/be-yourself/","publishdate":"2020-01-17T10:10:10Z","relpermalink":"/post/be-yourself/","section":"post","summary":"Do you understand yourself?","tags":["Personal","Life"],"title":"Be yourself","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"When I was young, I used to put my hand in my shirt and tell others I had an arm amputation.\nI press the exit button every time I‚Äôm about to lose in a video game.\nI sleep with all stuffed animals so no one will be sad.\nI have a 6-color ballpoint pen and tried to press 6 at a time.\nI poured soda into the jars and pretended to be drinking.\nI hide behind the door to scare people, but sometimes leave because I feel so long no one has come or because of urination.\nI pretended to be asleep and let my dad carry me to bed. I think the moon follows my bike.\nI looked at the two small drops of rain on the window thinking that it was racing.\nI ate the fruit but accidentally swallowed the seed and then I was terrified of the fear that it would grow in my stomach.\nDo you remember the days we were young when we wished to grow up quickly?\nDo not know what we have thought?\nDo you still think so now?\n(The Blue Lagoon)\n","date":1577527810,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577527810,"objectID":"304f49f623eb03203e1b23ea5352f7fb","permalink":"https://martinakaduc.github.io/post/childhood/","publishdate":"2019-12-28T10:10:10Z","relpermalink":"/post/childhood/","section":"post","summary":"Do you remember your childhood?","tags":["Personal","Life"],"title":"Childhood","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"Happiness is an invisible thing, so you cannot use reason to find and possess it but your heart. In this journey to find happiness, just wish you always remember that you have a heart, from which to keep your heart always fire. Because a good heart works when it keeps its emotional beats, not its bare beats just because it‚Äôs a part of the body. With it, you can feel what happiness really is.\n","date":1576577410,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576577410,"objectID":"0f171f2a8d38d5766dbdca66cc86693b","permalink":"https://martinakaduc.github.io/post/time-to-be-happy/","publishdate":"2019-12-17T10:10:10Z","relpermalink":"/post/time-to-be-happy/","section":"post","summary":"What is happiness?","tags":["Personal","Life"],"title":"Time to be happy","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"[This post is written for literarians, or fathers or mothers who have had intention of divorce]\nMentioning white color, most people think of children in pure white shirts going to school every day, or unblemished and spontaneous things like a 3-year-old kid‚Äôs soul. But it‚Äôs just the tip of the iceberg, white is an extreme obsession for those is suffering severe trauma. In Le Quynh Tran‚Äôs eyes, the scariest moment of white is when family affection has begun to be rifted.\nLove is like a tale\nFather has long since not read.\nLove is like a friend\nMother has not met for long.\nA white window\nA girl with hidden tears\nStars are falling outside\nIn a night of twinkle moonlight.\nIn the first comparison ‚ÄúLove is like a tale‚Äù, the composer half opens a world full of magic. But why does he compare love with tale? Maybe because tale is about miraculous world of kids and love is about the magic between parents. The magic of love connects and leads them to be a father and to be a mother. But in the story that the father has forgotten, may that magic just get faded?\nThe next comparison is much more ordinary. Love is like a friend but ‚Äúlong time no see‚Äù, it‚Äôs unforgettable but so distant. We doubtfully understand that love between ‚Äúfather‚Äù and ‚Äúmother‚Äù has not been fervid as before. The song‚Äôs melody also partly reveals that emotion‚Äôs disappearance, we find that when being set to music, the comma is transformed from text punctuation to a silent sound which is so fast but also motionless, a silent sound is enough for listeners to feel the pain of ‚Äúa girl‚Äù.\nLe Quynh Tran continues to insert some details illustrating the real-life tragedy of that family to his music story.\nBehind each frosty word,\nTime still flies.\nBehind the happy smile,\nTears still fall when no one‚Äôs watching.\nPerhaps, the love between parents may not be so wonderful, instead, there are cold and apathetic words. All of those used to love so hard but they are now, with happy smiles on the outside, still blubbering when getting back home in lonely night. By song lyric, the composer also sends us a message about the love consolidation before time flies so fast and so far.\nAn empty house\nA sleepless night like sorrows in winter nights\nOr flowers are waiting for the spring to bloom.\nThe special story about a cold home of ‚Äúthe girl‚Äù is unveiled in a music space full of white color: ‚Äú√¥ c·ª≠a tr·∫Øng‚Äù (white window), ‚Äúƒë√™m tr·∫Øng‚Äù (it means sleepless night, but ‚Äútr·∫Øng‚Äù also means ‚Äúwhite‚Äù). But why it is ‚Äúƒë√™m tr·∫Øng‚Äù? We get used to the word ‚Äúƒë√™m tr·∫Øng‚Äù (sleepless night) as a description of the sleeplessness in anxiety. But using the word ‚Äútr·∫Øng ƒë√™m‚Äù (being sleepless for the whole night) to describe a girl‚Äôs sleeplessness seems too mature for her age. The word ‚Äúƒë√™m tr·∫Øng‚Äù brings about purity and innocence but a little glumness and loneliness in frigid winter nights.\nLe Quynh Tran always has subtly deep comparisons. He compares ‚Äúƒë√™m tr·∫Øng‚Äù - a cold color with ‚Äúsorrow‚Äù in winter nights - an emotion. With compact words, although not imagining the realistic white color of a sleepless night, we can partly feel for the unfortunate girl‚Äôs painful soul which is made by her lovers in her family.\nLe Quynh Tran‚Äôs music really makes a special impression of a personal feeling in music lover‚Äôs hearts. It is sad but not suffocating, just vague and quite anxious.\nFalling asleep, she is dreaming about being a swift flying in the mist,\nAcross the ocean\nFlying to remote galaxy.\nWith a kind heart, the composer doesn‚Äôt want ‚Äúthe innocent girl‚Äù to undergo the sadness when her house is not a home in the true sense of the word. He transforms her sorrow into a beautiful dream with little daisy waiting for the spring to bloom. In reality, we may not able to magic an obsessed sleepless night into happiness. However, the artist, with music in particular and art in general, can turn that into kid‚Äôs dreams looking alike folks told by the melody. That is a beautiful dream with swifts flying in the sky, across the boundless ocean, across verdant forests and interminable Mongolian grasslands and reach to the new region, where the girl would have both of a happy family and parent‚Äôs love. ‚ÄúWhite‚Äù tends to repel sadness, which seems like the story ‚ÄúThe Little Match Girl‚Äù of Andersen.\nThe adults in our challenging growth may lose the passionate love of the youth in our heart. The composer reminds us of the most careless and beautiful period when we still believed in that magic. Why do the parents really want to steal the happy-go-lucky world of their children?\nThe last hidden intention of Quynh is to wake parental vocation in adults. He would like to send a message that for a kid, white should not be the color of sleepless nights or terrifying nightmares, instead, it should be the purity of ‚Äúgentle dreams staying in the heart‚Äù. Images about ‚Äúhome‚Äù, ‚Äúswifts‚Äù and ‚Äúthe spring‚Äù will be the representative of happiness, reunion and coziness of a family.\nLet the white\nLike gentle dreams staying in the heart\nAnd in the ‚Ä¶","date":1575108610,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575108610,"objectID":"c1baa2754e442841ba9bd41a9666adb0","permalink":"https://martinakaduc.github.io/post/the-white/","publishdate":"2019-11-30T10:10:10Z","relpermalink":"/post/the-white/","section":"post","summary":"A song about children written for adults","tags":["Personal","Life"],"title":"Is white the color of purity and innocence?","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"üê∑I think carefully, this is money collected from other people. Suppose I won and I got the money, the money is still unrighteous, because I don‚Äôt work to get it. I didn‚Äôt make anyone proud. Then everyone will look at our home: ‚ÄúThat‚Äôs lucky, it‚Äôs lucky ‚Ä¶‚Äù I don‚Äôt need that. I need to make myself worthy of the value of a person in the society. I think the next time if I was lucky, I would refuse.\nüêîWhy are you so foolish? You keep saying that. If so, you have to bring it back‚Ä¶\nüê∑ No, I don‚Äôt need it. You should not need either. Because when I grow up, I will take care of your grandchildren, they have to become kind and proud persons. Speaking of themselves, when they reveal themselves to outsiders, they need be proud instead of hidden. They should be really proud of themselves instead of proving their pride. And although no one is proud of them, their parents can be proud of them.\nCredit: Oopsy psychology and psychotherapy community\n","date":1570183810,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570183810,"objectID":"11a7b16864f8a090b913c71317adf2c7","permalink":"https://martinakaduc.github.io/post/burning-lottery-ticket/","publishdate":"2019-10-04T10:10:10Z","relpermalink":"/post/burning-lottery-ticket/","section":"post","summary":"A lottery ticket is a ticket that can be used to win a prize, especially in a lottery, a form of gambling. But what if you won a lottery ticket but you burned it?","tags":["Personal","Life"],"title":"Try talking to everyone in your family that you have won a lottery ticket but bruned it","type":"post"},{"authors":["Duc Q. Nguyen"],"categories":["Life"],"content":"First let‚Äôs talk about Shizuka. Shizuka embodies the ideal type of lover that every man desires. Specifically because she‚Äôs beautiful, has her own personality, a good education and is an excellent housewife. Why did a girl like that choose a clumsy like Nobita? In the meantime, she had many more options: perfect Dekisugi, rich Suneo and energetic Jaian? Could it be that Nobita has something more special than the others or is it because Shizuka really doesn‚Äôt fit the other three? Let‚Äôs analyze together!\nThe first and also the most formidable rival is Dekisugi. This boy presents a well-educated person with perfect virtue. Why is that? Because in all fields from studying, playing sports or relationships in life, Dekisugi does very well. (There are episodes that Nobita tried to demolish him but he still did not fall below the level of quite good) Shizuka liked Dekisugi, they also have many times going out together, doing homework‚Ä¶ so why didn‚Äôt she choose Dekisugi in the end? Surely anyone who has seen Doraemon can admit that it is very rare he joined group games with friends. Every time Shizuka is in danger, Nobita comes to the rescue. That‚Äôs enough for us to consider that Dekisugi - a perfect human model should only be a dream, worthy of idol, friendzone rather than a lover.\nNext is the rich young-master Suneo. Rich background, Suneo has a life fulfilled with comfort, material. If Shizuka married Suneo, she would surely be a royal maid. Is that true? And does Shizuka like that kind of life? The answer is probably not. We easily see that due to the lack of familiarity in the family, when facing the danger, Suneo often chooses to escape and leave others. In addition, he is also boastful, very peachy and heavily dependent on his mother (each time he need help, he always calls his mother). Perhaps for all of that reasons, Shizuka put Suneo in friendzone. üòÉ\nThe person with the most courage and strength in the group is Jaian. Talking about Jaian, we must talk about spirit. We often see that Jaian bullies his friends very easily. But that was probably due to the genes and habitat that shaped his personality. When confronted with danger, with events in life, do we realize the nature of him. It can be said that in dangerous adventures with the group, many times Jaian was the brave person who rushed into danger, led the team. When he parted aways with Nobita, he regretted everything he did or many times for his sister that he could do anything. Thereby, we can see that Jaian is a man who is an upright man, meaning but in a rude manner. The reason that Shizuka only considered Jaian as a friend was probably because of his personality. A gentle girl will surely not choose people who are too shocked and rude. üôÇ\nAnd finally, it is Nobita Nobi. He has many shortcomings including: lazy, sleepy, bad at school, bad sports‚Ä¶ But is that all about Nobita‚Äôs people? The answer is definitely not :))) From the beginning, Nobita was always the most meaningful person. It is easy to see, in all of Doraemon‚Äôs long episodes, Nobita was always the one who saw through the inside of the supporting characters. He is always a personal talker, sympathetic to the supporting characters. This is a trait that the other 3 guys don‚Äôt have. Not only that, he‚Äôs also a very tolerant, tolerates person who bullies himself (there are times when he sought revenge, but compared to the number of times he was bullied, it‚Äôs not worth), tolerates each blade of grass. He is also very brave to protect the right, always trying his best to do something if he has made up his determination. Back to Nobita‚Äôs bad study, if we noticed that most of the problems were true and false, Nobita could choose all the wrong answers, this is not normal :)))\nWe go back to Shizuka. She and Nobita have always been together in every adventure, growing up and growing together. Nobita was always a support for Shizuka whenever she was in trouble. (It is easy to understand, because no one can leave the person who makes her happy) It can be consider that Nobita is the present and the future that Shizuka should respect. Because of Nobita‚Äôs appearance, Shizuka becomes more perfect. Human psychology is very complex and accepting a person who makes silly harmless mistakes both helps us feel good and helps us accept the person who is defective in us. If staying with Dekisugi, Shizuka will forever be a shadow of herself, but going with Nobita, she is a true woman that thousands of people dream about. Love is complex, we don‚Äôt need the perfect person, the one we need the most is the right person to accompany us all the way of life. And maybe Shizuka chose the right one.\nLadies, have you chosen a Nobita for your life?\n","date":1569838210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569838210,"objectID":"d4c3d52ff3de4a7f121f984413d8ab65","permalink":"https://martinakaduc.github.io/post/nobita-xuka/","publishdate":"2019-09-30T10:10:10Z","relpermalink":"/post/nobita-xuka/","section":"post","summary":"An inside of Shizuka's choices","tags":["Personal","Life"],"title":"Why did Shizuka choosen Nobita instead of Dekisugi, Suneo or Jaian?","type":"post"}]