<!doctype html><!-- This site was created with Hugo Blox. https://hugoblox.com --><!-- Last Published: September 26, 2025 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script><link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href=/css/wowchemy.f6689966c0a10712f95f034011917db0.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Truong Quang Vo"><meta name=description content="Academic profile of Truong Quang Vo - MS student in Machine Learning at Northwestern University."><link rel=alternate hreflang=en-us href=https://tqv24.github.io/><link rel=canonical href=https://tqv24.github.io/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu263ca39e98b046b5641ca652ce5a1514_340372_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu263ca39e98b046b5641ca652ce5a1514_340372_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@tqv24"><meta property="twitter:creator" content="@tqv24"><meta property="twitter:image" content="https://tqv24.github.io/media/icon_hu263ca39e98b046b5641ca652ce5a1514_340372_512x512_fill_lanczos_center_3.png"><meta property="og:type" content="profile"><meta property="og:site_name" content="Truong Quang Vo"><meta property="og:url" content="https://tqv24.github.io/"><meta property="og:title" content="Truong Quang Vo"><meta property="og:description" content="MS student in Machine Learning at Northwestern University specializing in LLM evaluation, alignment, and synthetic data generation."><meta property="og:image" content="https://martinakaduc.github.io/media/icon_hu263ca39e98b046b5641ca652ce5a1514_340372_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2025-09-17T14:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://martinakaduc.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://martinakaduc.github.io/"}</script><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script><link rel=alternate href=/index.xml type=application/rss+xml title="Truong Quang Vo"><title>Truong Quang Vo</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand hreTruong Quang Vo</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Truong Quang Vo</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/post><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/event><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/uploads/martin_resume.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" width=270 height=270 src=/authors/admin/avatar_hudd8c4698ec65c88ae96d5a127f959223_826709_270x270_fill_q75_lanczos_center.jpg alt="Truong Quang Vo"><div class=portrait-title><h2>Truong Quang Vo</h2><h3>MS Student in Machine Learning</h3><h3><a href=https://www.northwestern.edu/ target=_blank rel=noopener><span>Northwestern University</span></a></h3></div><ul class=network-icon aria-hidden=truvoquangtruong152000@gmail.com aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href=https://twitter.com/tqv24 target=_blank rel=noopener aria-label=twitter><i class="fab fa-twitter big-icon"></i></a></li><li><a href="https://scholar.google.com/" target=_blank rel=noopener aria-label=graduation-cap><i class="fas fa-graduation-cap big-icon"></i></a></li><li><a href=https://github.com/tqv24 target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/tqv24n.com/in/martinakaduc/ target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>Biography</h1><div class=article-style><p style=text-align:justify>Duc Q. Nguyen, also known as Martin Nguyen, is currently a first‑year PhD student driven by a vision to amplify human potential throughTruong Quang Vo is an MS student in Machine Learning and Data Science at Northwestern University (expected graduation: December 2025). His research focuses on developing fine-grained evaluation frameworks for LLMs, generating synthetic data to refine model behaviors, and advancing efficient machine learning algorithms for large-scale training. He is currently a Visiting Student Researcher at Stanford University's Trustworthy AI Research Lab, working with <a href=https://cs.stanford.edu/~sanmi/ target=_blank rel=noopener>Professor Sanmi Koyejo</a> on cross-cultural understanding in large language models.</p><p style=text-align:justify>His research aims to develop rigorous methodologies and scalable techniques that strengthen the reliability and trustworthiness of language models.</p><p><i class="fas fa-download pr-1 fa-fw"></i> Download
<a href=/uploads/Truong_Vo_CV.pdf target=_blank>CV</a>
.</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Generative Models</li><li>Graph Representation Learning</li><li>Probabilistic Machine Learning</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>B.Eng. in Computer Science, 2022</p><p class=institution>Ho Chi Minh City University of Technology</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>M.Eng. in Computer Science, 2025</p><p class=institution>Ho Chi Minh City University of Technology</p></div></li></ul></div></div></div></div></div></section><section id=experience class="home-section wg-experience"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Experience</h1></div><div class="col-12 col-lg-8"><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class=col>&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.cs.stanford.edu target=_blank rel=noopener><img src=/media/icons/brands/stanford.svg width=56 height=56 alt="Stanford University" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Visiting Student Researcher</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.cs.stanford.edu target=_blank rel=noopener>Stanford University</a></div><div class="text-muted exp-meta">Sep 2024 –
Dec 2024
<span class=middot-divider></span>
<span>Stanford, CA, USA</span></div></div></div><div class=card-text>I was working at <a href=https://stair.cs.stanford.edu/tLLM Evaluation & Alignment</li><li>Synthetic Data Generation</li><li>Efficient Machine Learning</li><li>Trustworthy AI</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>M.S. in Machine Learning and Data Science, 2025</p><p class=institution>Northwestern University (GPA: 3.98/4.0)</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>B.S. in Chemical Engineering, 2023</p><p class=institution>Drexel University (GPA: 3.77/4.0)=/media/icons/brands/hcmut.svg width=56 height=56 alt="Assoc. Prof. Tho Quan" loading=lazy></div><div><div class="section-subheading card-title exp-title text-muted my-0">Research Assistant</div><div class="section-subheading card-title exp-company text-muted my-0">Assoc. Prof. Tho Quan</div><div class="text-muted exp-meta">Feb 2022 –Trustworthy AI Research Lab</a></div><div class="text-muted exp-meta">Jun 2025 –
Present
<span class=middot-divider></span>
<span>Stanford, CA, USA</span></div></div></div><div class=card-text>Developed cultural reasoning benchmark (80K+ prompts) integrated into HELM Leaderboard. Fine-tuned LLMs with SFT and PPO for cultural alignmentch Group</a>.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class=col>&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.cse.hcmut.edu.vn targetNorthwestern University" loading=lazy></div><div><div class="section-subheading card-title exp-title text-muted my-0">Graduate Research Assistant</div><div class="section-subheading card-title exp-company text-muted my-0">Center for Deep Learning, Northwestern University</div><div class="text-muted exp-meta">Jun 2024 –
May 2025
<span class=middot-divider></span>
<span>Evanston, IL, USA</span></div></div></div><div class=card-text>Built synthetic clinical data pipeline for rare ICD codes. Developed efficient boosting algorithms for CNN/Transformer ensemblester Science</a>.</div></div></div></div></div></div></div></div></section><section id=accomplishments class="home-section wg-accomplishments"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Accomplish­ments</h1></div><div class="col-12 col-lg-8"><div class="card experience course"><div class=card-body><div class="d-flex align-content-start"><div classimg src=/media/icons/brands/hcmut.svg width=56 height=56 alt="Sabre Holdings" loading=lazy></div><div><div class="section-subheading card-title exp-title text-muted my-0">AI Engineer Intern</div><div class="section-subheading card-title exp-company text-muted my-0">Sabre Holdings</div><div class="text-muted exp-meta">Sep 2025 –
Present
<span class=middot-divider></span>
<span>Remote</span></div></div></div><div class=card-text>Developed multi-agent AI system with AutoGen for personalized air travel recommendations. Integrated SendGrid API for automated communication pipeline/div></div><div class="card experience course"><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.hcmut.edu.vn target=_blank rel=noopener><img src=/media/icons/brands/hcmut.svg width=56 height=56 alt=HCMUT loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Certificate of Typical Student</div><div class="card-subtitle my-0 article-metadata"><a href=https://www.hcmut.edu.vn target=_blank rel=noopener>HCMUT</a><span class=middot-divider></span>
Dec 2020</div></div></div><div class=card-text>Bach Khoa Youth Award 2020</div><a class=card-link href=uploads/Typical_Student.pdf target=_blank rel=noopener>See certificate</a></div></div><div class="card experience course"><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://ict-hcm.gov.vn target=_blank rel=noopener><img src=/media/icons/brands/hcmc_department_of_information_and_communication.svg width=56 height=56 alt="HCMC Department of Information and Communication" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Certificate of Merit</div><div class="card-subtitle my-0 article-metadata"><a href=https://ict-hcm.gov.vn target=_blank rel=noopener>HCMC Department of Information and Communication</a><span class=middot-divider></span>
Dec 2019</div></div></div><div class=card-text>Student with excellent achievements in Artificial Intelligence research</div><a class=card-link href=uploads/SVAI_2019.pdf target=_blank rel=noopener>See certificate</a></div></div></div></div></div></section><section id=posts class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent Posts</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/phd-application/>The Prolonged Uncertainty of the PhD Application Period: Hope and Resilience</a></div><a href=/post/phd-application/ class=summary-link><div class=article-style>The process of applying for a PhD program is such a Schrödinger&rsquo;s cat experiment.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted>Duc Q. Nguyen</span></div><span class=article-date>Mar 27, 2025
</span><span class=middot-divider></span>
<span class=article-reading-time>5 min read
</span><span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/academic/>Academic</a></span></div></div></div><div class=ml-3><a href=/post/phd-application/><img src=/post/phd-application/featured_hu6c21644c695b31a9399f39b4fe379554_156080_51dc01e5f3a57b4835889b331dfa8971.webp height=113 width=150 alt="The Prolonged Uncertainty of the PhD Application Period: Hope and Resilience" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/mixsura-gemsura/>Breaking Ground in Vietnamese Language Models</a></div><a href=/post/mixsura-gemsura/ class=summary-link><div class=article-style>Revolutionizing natural language processing with MixSUra and GemSUra, our latest Vietnamese language models.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted>Duc Q. Nguyen</span></div><span class=article-date>Mar 12, 2024
</span><span class=middot-divider></span>
<span class=article-reading-time>1 min read
</span><span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a>, <a href=/category/natural-language-processing/>Natural Language Processing</a></span></div></div><div class=btn-links></div></div><div class=ml-3><a href=/post/mixsura-gemsura/><img src=/post/mixsura-gemsura/featured_hu5193bdbd96c8fd69133afc86bc1e5c06_353173_ed2673cc2a8dc561a2dee8a7978ded5a.webp height=150 width=150 alt="Breaking Ground in Vietnamese Language Models" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/ura-llama-announcement/>URA-LLaMa</a></div><a href=/post/ura-llama-announcement/ class=summary-link><div class=article-style>First release of URA-LLaMa, a series of large language models for Vietnamese.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><div><span class=author-highlighted>Duc Q. Nguyen</span></div><span class=article-date>Oct 10, 2023
</span><span class=middot-divider></span>
<span class=article-reading-time>1 min read
</span><span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a>, <a href=/category/natural-language-processing/>Natural Language Processing</a></span></div></div><div class=btn-links></div></div><div class=ml-3><a href=/post/ura-llama-announcement/><img src=/post/ura-llama-announcement/featured_hu1eb917ba7be60c6d75dc9d6d55dd232e_1057945_cc0aa9b8e9de70058774160b2a55dc4a.webp height=150 width=150 alt=URA-LLaMa loading=lazy></a></div></div><div class=see-all><a href=/post/>See all posts
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=projects class="home-section wg-portfolio"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Projects</h1></div><div class="col-12 col-lg-8"><span class="d-none default-project-filter">*</span><div class=project-toolbar><div class=project-filters><div class=btn-toolbar><div class="btn-group flex-wrap"><a href=# data-filter=* class="btn btn-primary btn-lg active">All</a>
<a href=# data-filter=.js-id-artificial-intelligence class="btn btn-primary btn-lg">Artificial Intelligence</a>
<a href=# data-filter=.js-id-computational-biology class="btn btn-primary btn-lg">Computational Biology</a>
<a href=# data-filter=.js-id-graph-representation-learning class="btn btn-primary btn-lg">Graph Representation Learning</a>
<a href=# data-filter=.js-id-other class="btn btn-primary btn-lg">Other</a></div></div></div></div><div class="isotope projects-container row js-layout-row"><div class="col-12 isotope-item js-id-deep-learning js-id-natural-language-processing"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/large_language_models/>Large Language Models and Applications</a></div><a href=/project/large_language_models/ class=summary-link><div class=article-style>Large language models have achieved state-of-the-art results on many natural language processing tasks. I am interested in developing new large language models and applying them to solve real-world problems.</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://huggingface.co/ura-hcmut target=_blank rel=noopener><i class="fas fa-grin mr-1"></i>Follow HuggingFace</a></div></div><div class=ml-3></div></div></div><div class="col-12 isotope-item js-id-deep-learning js-id-graph-theory js-id-graph-representation-learning"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/graph_theory/>Solving Graph Theory Problems</a></div><a href=/project/graph_theory/ class=summary-link><div class=article-style>Graph is a powerful data structure that can be used to model many real-world problems. In this project, I will explore how to use Deep Learning to solve graph theory problems.</div></a><div class="stream-meta article-metadata"></div></div><div class=ml-3></div></div></div><div class="col-12 isotope-item js-id-deep-learning js-id-drug-discovery js-id-graph-representation-learning js-id-language-models"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/drug_discovery/>Drug Discovery</a></div><a href=/project/drug_discovery/ class=summary-link><div class=article-style>Drug discovery is a complex, expensive, and time-consuming process. I am interested in solving problems in drug discovery using deep learning to accelerate the process of drug development.</div></a><div class="stream-meta article-metadata"></div></div><div class=ml-3></div></div></div></div></div></div></div></section><section id=talks class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent & Upcoming Talks</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/a-practical-introduction-to-the-rational-speechact-modeling-framework/>A Practical Introduction to The Rational SpeechAct Modeling Framework</a></div><a href=/talk/a-practical-introduction-to-the-rational-speechact-modeling-framework/ class=summary-link><div class=article-style>A seminar introducing the Rational Speech Act framework, which models language understanding as recursive Bayesian inference.</div></a><div class="stream-meta article-metadata"><div><span>Sep 17, 2025 2:00 PM &mdash; 3:00 PM
</span><span class=middot-divider></span>
<span>COM3-02-60</span></div><div><span class=author-highlighted>Duc Q. Nguyen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://colab.research.google.com/drive/18JL1cvatSirpj_LL2mBeN5pvRcb-H5rN?usp=sharing" target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/slides/Rational_Speech_Act.pdf target=_blank rel=noopener>Slides</a></div></div><div class=ml-3><a href=/talk/a-practical-introduction-to-the-rational-speechact-modeling-framework/><img src=/talk/a-practical-introduction-to-the-rational-speechact-modeling-framework/featured_hu43b391f704cbf4ce81408f509b11b990_98289_b8a94b7b99cb2ddf3c0866449eeaa758.webp height=100 width=150 alt="A Practical Introduction to The Rational SpeechAct Modeling Framework" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/llms-get-lost-in-multi-turn-conversation/>LLMs Get Lost In Multi-Turn Conversation</a></div><a href=/talk/llms-get-lost-in-multi-turn-conversation/ class=summary-link><div class=article-style>A seminar about evaluating how large language models degrade in performance during multi-turn conversations due to premature assumptions and context loss.</div></a><div class="stream-meta article-metadata"><div><span>Aug 29, 2025 2:00 PM &mdash; 3:00 PM
</span><span class=middot-divider></span>
<span>COM3-B1-15</span></div><div><span class=author-highlighted>Duc Q. Nguyen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/slides/Multiturn_LLM.pdf target=_blank rel=noopener>Slides</a></div></div><div class=ml-3><a href=/talk/llms-get-lost-in-multi-turn-conversation/><img src=/talk/llms-get-lost-in-multi-turn-conversation/featured_hu8ffc3a718e34315ed7acece2e59112bc_741091_afac3edfe81cc1051e1244afbf9e963b.webp height=154 width=150 alt="LLMs Get Lost In Multi-Turn Conversation" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/bayesian-theory-of-mind/>Bayesian Theory of Mind</a></div><a href=/talk/bayesian-theory-of-mind/ class=summary-link><div class=article-style>A seminar for discussing the recent Bayesian Theory of Mind paper.</div></a><div class="stream-meta article-metadata"><div><span>Aug 20, 2025 2:00 PM &mdash; 3:00 PM
</span><span class=middot-divider></span>
<span>COM3-02-60</span></div><div><span class=author-highlighted>Duc Q. Nguyen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/slides/BToM.pdf target=_blank rel=noopener>Slides</a></div></div><div class=ml-3><a href=/talk/bayesian-theory-of-mind/><img src=/talk/bayesian-theory-of-mind/featured_hu53be832d120045dab8768a10b4bcf1b5_97041_96f8130c7bb70bc0188e05a7ea25bff3.webp height=150 width=150 alt="Bayesian Theory of Mind" loading=lazy></a></div></div><div class=see-all><a href=/event/>See all events
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=featured class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Featured Publications</h1></div><div class="col-12 col-lg-8"><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Duc Q. Nguyen</span>, <span>Thanh Toan Nguyen</span>, <span>Jun Jo</span>, <span>Florent Poux</span>, <span>Shikha Anirban</span>, <span>Tho T. Quan</span></div><span class=article-date>September, 2024
</span><span class=middot-divider></span>
<span class=pub-publication>IEEE Access
</span><span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a>, <a href=/category/graph-representation-learning/>Graph Representation Learning</a></span></div><a href=/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/><div class=img-hover-zoom><img src=/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/featured_huc413adafd5021d2d18458ab8f59fb551_562338_6bc65e105eca17ed3a17c7a5cd8136dd.webp height=455 width=808 class=article-banner alt="Explainable Neural Subgraph Matching With Learnable Multi-Hop Attention" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/>Explainable Neural Subgraph Matching With Learnable Multi-Hop Attention</a></div><a href=/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/ class=summary-link><div class=article-style><p>Subgraph matching is a challenging problem with a wide range of applications in drug discovery, social network analysis, biochemistry, and cognitive science. It involves determining whether a given query graph is present within a larger target graph. Traditional graph-matching algorithms provide precise results but face challenges in large graph instances due to the NP-complete nature of the problem, limiting their practical applicability. In contrast, recent neural network-based approximations offer more scalable solutions but often lack interpretable node correspondences. To address these limitations, this article presents a multi-task learning framework called xNeuSM: Explainable Neural Subgraph Matching, which introduces Graph Learnable Multi-hop Attention Networks (GLeMA) that adaptively learn the parameters governing the attention factor decay for each node across hops rather than relying on fixed hyperparameters. Our framework jointly optimizes both subgraph matching and finding subgraph-isomorphism mappings. We provide a theoretical analysis establishing error bounds for GLeMA’s approximation of multi-hop attention as a function of the number of hops. Additionally, we prove that learning distinct attention decay factors for each node leads to a correct approximation of multi-hop attention. Empirical evaluation on real-world datasets shows that xNeuSM achieves substantial improvements in prediction F1 score of up to 34% compared to approximate baselines and, notably, at least a seven-fold faster query time than exact algorithms. With these results, xNeuSM can be applied to solve matching problems in various domains spanning from biochemistry to social science</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/explainable-neural-subgraph-matching-with-learnable-multi-hop-attention/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1109/ACCESS.2024.3458050 target=_blank rel=noopener>DOI</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span>Sang T. Truong</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Duc Q. Nguyen</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Toan Nguyen</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Dong D. Le</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Nhi N. Truong</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Tho Quan</span>, <span>Sanmi Koyejo</span></div><span class=article-date>June, 2024
</span><span class=middot-divider></span>
<span class=pub-publication>In <em>Proceddings of 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics</em>
</span><span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a></span></div><a href=/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/><div class=img-hover-zoom><img src=/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/featured_hua93ab913a56f7a4e45495bef38a4c8ca_767458_b554e15aafb699cb01cb3db15d34fc50.webp height=455 width=808 class=article-banner alt="Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/>Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models</a></div><a href=/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/ class=summary-link><div class=article-style><p>Recent advancements in large language models (LLMs) have underscored their importance in the evolution of artificial intelligence. However, despite extensive pretraining on multilingual datasets, available open-sourced LLMs exhibit limited effectiveness in processing Vietnamese. The challenge is exacerbated by the absence of systematic benchmark datasets and metrics tailored for Vietnamese LLM evaluation. To mitigate these issues, we have finetuned LLMs specifically for Vietnamese and developed a comprehensive evaluation framework encompassing 10 tasks and 31 metrics. We observe that finetuning can help LLMs transfer knowledge across languages, serving as an efficient way to bolster their capabilities in non-English languages. Moreover, our analysis indicates that larger models can introduce more biases and uncalibrated outputs and the key factor influencing LLM performance is the quality of the training or finetuning datasets. These insights underscore the significance of meticulous finetuning with high-quality datasets in enhancing LLM performance.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/crossing-linguistic-horizon-finetuning-and-evaluation-vietnamese-llms/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.18653/v1/2024.findings-naacl.182 target=_blank rel=noopener>DOI</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Duc Q. Nguyen</span>, <span>Nghia Q. Vo</span>, <span>Thinh T. Nguyen</span>, <span>Khuong Nguyen-An</span>, <span>Quang H. Nguyen</span>, <span>Dang N. Tran</span>, <span>Tho T. Quan</span></div><span class=article-date>May, 2022
</span><span class=middot-divider></span>
<span class=pub-publication>Scientific Reports
</span><span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a></span></div><a href=/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/><div class=img-hover-zoom><img src=/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/featured_hu17e4ce99024e5ce3f7e99387442ead7b_790825_03ada11663a2af389916db63b4ee0caf.webp height=455 width=808 class=article-banner alt="BeCaked: An Explainable Artificial Intelligence Model for COVID-19 Forecasting" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/>BeCaked: An Explainable Artificial Intelligence Model for COVID-19 Forecasting</a></div><a href=/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/ class=summary-link><div class=article-style><p><p>From the end of 2019, one of the most serious and largest spread pandemics occurred in Wuhan (China) named <em>Coronavirus</em> (COVID-19). As reported by the World Health Organization, there are currently more than 100 million infectious cases with an average mortality rate of about five percent all over the world. To avoid serious consequences on people&rsquo;s lives and the economy, policies and actions need to be suitably made in time. To do that, the authorities need to know the future trend in the development process of this pandemic. This is the reason why forecasting models play an important role in controlling the pandemic situation. However, the behavior of this pandemic is extremely complicated and difficult to be analyzed, so that an effective model is not only considered on accurate forecasting results but also the explainable capability for human experts to take action pro-actively.</p><p>With the recent advancement of <em>Artificial Intelligence</em> (AI) techniques, the emerging <em>Deep Learning</em> (DL) models have been proving highly effective when forecasting this pandemic future from the huge historical data. However, the main weakness of DL models is lacking the explanation capabilities. To overcome this limitation, we introduce a novel combination of the <em>Susceptible-Infectious-Recovered-Deceased</em> (SIRD) compartmental model and <em>Variational Autoencoder</em> (VAE) neural network known as BeCaked. With pandemic data provided by the Johns Hopkins University Center for Systems Science and Engineering, our model achieves $0.98$ $R^2$ and $0.012$ $MAPE$ at world level with $31$-step forecast and up to $0.99$ $R^2$ and $0.0026$ $MAPE$ at country level with $15$-step forecast on predicting daily infectious cases. Not only enjoying high accuracy, but BeCaked also offers useful justifications for its results based on the parameters of the SIRD model. Therefore, BeCaked can be used as a reference for authorities or medical experts to make on time right decisions.</p></p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/becaked-an-explainable-artificial-intelligence-model-for-covid-19-forecasting/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1038/s41598-022-11693-9 target=_blank rel=noopener>DOI</a></div></div></div></div></div></section><section id=publications class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent Publications</h1></div><div class="col-12 col-lg-8"><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Duc Nguyen</span>, <span>Dong Le</span>, <span>Long Nguyen</span>, <span>Quyen Vu</span>, <span>Tran Le</span>, <span>Dung Nguyen</span>, <span>Nga Huynh</span>, <span>Huong Nguyen</span>, <span>Phat Tran</span>, <span>Dang Le</span>, <span>Sang Truong</span>, <span>Sanmi Koyejo</span>, <span>Cuong Le</span>, <span>Tho Quan</span>
</span>(2025).
<a href=/publication/riding-on-the-back-of-a-whale/>Riding on The Back of A Whale: A Hackathon Framework for Introducing High School Students to Large Language Models</a>.
AIED 2025.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/riding-on-the-back-of-a-whale/riding-on-the-back-of-a-whale.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/riding-on-the-back-of-a-whale/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Sang T. Truong</span>, <span class=author-highlighted>Duc Q. Nguyen</span>, <span>Willie Neiswanger</span>, <span>Ryan-Rhys Griffiths</span>, <span>Stefano Ermon</span>, <span>Nick Haber</span>, <span>Sanmi Koyejo</span>
</span>(2025).
<a href=/publication/neural-nonmyopic-bayesian-optimization-in-dynamic-cost-settings/>Neural Nonmyopic Bayesian Optimization in Dynamic Cost Settings</a>.
ICLR 2025 Workshop: Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/neural-nonmyopic-bayesian-optimization-in-dynamic-cost-settings/neural-nonmyopic-bayesian-optimization-in-dynamic-cost-settings.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/neural-nonmyopic-bayesian-optimization-in-dynamic-cost-settings/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Nhi Ngoc Truong</span>, <span class=author-highlighted>Duc Q. Nguyen</span>, <span>Jeffrey Gropp</span>, <span>Sang T. Truong</span>
</span>(2024).
<a href=/publication/hybrid-transformer-and-holt-winter/>Hybrid Transformer and Holt-Winter's Method for Time Series Forecasting</a>.
ICLR 2024 Workshop on Learning from Time Series For Health.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/hybrid-transformer-and-holt-winter/hybrid-transformer-and-holt-winter.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/hybrid-transformer-and-holt-winter/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Hoang Nhat Khang Vo</span>, <span>Duc Dong Le</span>, <span>Tran Minh Dat Phan</span>, <span>Tan Sang Nguyen</span>, <span>Quoc Nguyen Pham</span>, <span>Ngoc Oanh Tran</span>, <span class=author-highlighted>Duc Q. Nguyen</span>, <span>Tran Minh Hieu Vo</span>, <span>Tho Quan</span>
</span>(2024).
<a href=/publication/revitalizing-bahnaric-language-through-neural-machine-translation/>Revitalizing Bahnaric Language through Neural Machine Translation:Challenges, Strategies, and Promising Outcomes</a>.
In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/revitalizing-bahnaric-language-through-neural-machine-translation/revitalizing-bahnaric-language-through-neural-machine-translation.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/revitalizing-bahnaric-language-through-neural-machine-translation/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1609/aaai.v38i21.30385 target=_blank rel=noopener>DOI</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Tho Quan Thanh</span>, <span>Giang Dinh Lu</span>, <span class=author-highlighted>Duc Q. Nguyen</span>, <span>Hai Vu Hoang</span>, <span>Quy Nguyen Tran</span>, <span>Khoa Tran Ngoc Dang</span>, <span>Minh Tran Duy</span>
</span>(2023).
<a href=/publication/banava-a-cross-platform-ai-mobile-application-for-preserving-the-bahnaric-languages/>BaNaVA: A cross-platform AI mobile application for preserving the Bahnaric languages</a>.
BCD 2023.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/banava-a-cross-platform-ai-mobile-application-for-preserving-the-bahnaric-languages/banava-a-cross-platform-ai-mobile-application-for-preserving-the-bahnaric-languages.pdf target=_blank rel=noopener>PDF</a></p></div><div class=see-all><a href=/publication/>See all publications
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=tags class="home-section wg-tag-cloud"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Popular Topics</h1></div><div class="col-12 col-lg-8"><div class=tag-cloud><a href=/tag/academic/ style=font-size:.7rem>Academic</a>
<a href=/tag/applied-mathematics/ style=font-size:.7rem>Applied Mathematics</a>
<a href=/tag/artificial-intelligence/ style=font-size:1.3987413312616301rem>Artificial Intelligence</a>
<a href=/tag/bayesian-optimization/ style=font-size:.7rem>Bayesian Optimization</a>
<a href=/tag/bioinformatics/ style=font-size:1.009197964755307rem>Bioinformatics</a>
<a href=/tag/cognitive-science/ style=font-size:.7rem>Cognitive Science</a>
<a href=/tag/computational-models/ style=font-size:.7rem>Computational Models</a>
<a href=/tag/computational-science/ style=font-size:.7rem>Computational Science</a>
<a href=/tag/computer-science/ style=font-size:1.3987413312616301rem>Computer Science</a>
<a href=/tag/covid-19/ style=font-size:1.009197964755307rem>COVID-19</a>
<a href=/tag/deep-learning/ style=font-size:1.927318743273717rem>Deep Learning</a>
<a href=/tag/disease-modeling/ style=font-size:.7rem>Disease Modeling</a>
<a href=/tag/drug-discovery/ style=font-size:.7rem>Drug Discovery</a>
<a href=/tag/graph-neural-network/ style=font-size:1.5377753767673936rem>Graph Neural Network</a>
<a href=/tag/large-language-models/ style=font-size:1.655326987288515rem>Large Language Models</a>
<a href=/tag/life/ style=font-size:1.927318743273717rem>Life</a>
<a href=/tag/low-resource-language/ style=font-size:1.3987413312616301rem>Low-Resource Language</a>
<a href=/tag/natural-language-processing/ style=font-size:1.927318743273717rem>Natural Language Processing</a>
<a href=/tag/personal/ style=font-size:1.927318743273717rem>Personal</a>
<a href=/tag/time-series/ style=font-size:1.009197964755307rem>Time Series</a></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Contact</h1></div><div class="col-12 col-lg-8"><div class=mb-3><form name=contact method=POST action=https://formspree.io/f/xrgjwoga><div class="form-group form-inline"><label class=sr-only for=inputName>Name</label>
<input type=text name=name class="form-control w-100" id=inputName placeholder=Name required></div><div class="form-group form-inline"><label class=sr-only for=inputEmail>Email</label>
<input type=email name=email class="form-control w-100" id=inputEmail placeholder=Email required></div><div class=form-group><label class=sr-only for=inputMessage>Message</label>
<textarea name=message class=form-control id=inputMessage rows=5 placeholder=Message required></textarea></div><div class=d-none><label>Do not fill this field unless you are a bot: <input name=_gotcha></label></div><button type=submit class="btn btn-primary px-3 py-2 w-100">Send</button></form></div><ul class=fa-ul><li><i class="fa-li fas fa-envelope fa-2x" aria-hidden=true></i>
<span id=person-email><a href=mailto:nqduc@u.nus.edu>nqduc@u.nus.edu</a></span></li><li><i class="fa-li fas fa-map-marker fa-2x" aria-hidden=true></i>
<span id=person-address>13 Computing Drive, Singapore, 117417</span></li><li><i class="fa-li fas fa-compass fa-2x" aria-hidden=true></i>
<span>If you want to work with me, please email me and book a F2F meeting.</span></li><li><i class="fa-li fas fa-clock fa-2x" aria-hidden=true></i>
<span>Morning: 8 a.m. to 12 p.m.<br>Afternoon: 13 p.m. to 17 p.m.</span></li><li><i class="fa-li fas fa-calendar-check fa-2x" aria-hidden=true></i>
<a href=https://calendly.com/nqduc target=_blank rel=noopener>Book an appointment</a></li><li><i class="fa-li fab fa-twitter fa-2x" aria-hidden=true></i>
<a href=https://twitter.com/martinakaduc target=_blank rel=noopener>DM Me</a></li></ul></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2025 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> — the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.50933d940896e49f984a778650d5f7f5.js></script><script src=https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.7f5ebaff62ae468cff8bb3dd1337bb9b.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js type=module></script></body></html>